{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href='https://colab.research.google.com/github/prane-eth/AI_projects/blob/main/projects/LLM_fine-tuning.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUnsdLr1Dn-"
      },
      "source": [
        "### Project: Fine-tuning a language model\n",
        "\n",
        "Demo:\n",
        "![LLMs - Finetuning, RLAIF, and RLHF](../Demo/LLM_Fine-tuning.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aGqbJDNf1DoA"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    __import__('unsloth')\n",
        "except ImportError:\n",
        "\t# %%capture\n",
        "\t%pip install 'unsloth @ git+https://github.com/unslothai/unsloth.git'\n",
        "\t%pip install --no-deps 'xformers<0.0.26' trl tyro peft accelerate bitsandbytes\n",
        "\t%pip install torch==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "from datasets import Dataset\n",
        "from groq import Groq\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import TrainingArguments, set_seed\n",
        "from trl import SFTTrainer\n",
        "from unsloth import FastLanguageModel\n",
        "from common_functions import display_md, datasets_dir, RANDOM_STATE\n",
        "\n",
        "HOSTING_ENABLED = False\n",
        "\n",
        "set_seed(RANDOM_STATE)\n",
        "\n",
        "topic = 'customer_support'\n",
        "datasets_folder = os.path.join(datasets_dir, topic + '_bot')  # create sub-folder for the topic\n",
        "if not os.path.exists(datasets_folder):\n",
        "\tos.makedirs(datasets_folder)\n",
        "\n",
        "finetune_data_filepath = os.path.join(datasets_folder, f'finetune_data.csv')\n",
        "model_checkpoint_path = os.path.join(datasets_folder, f'saved_model')\n",
        "all_query_responses_filepath = os.path.join(datasets_folder, f'all_query_responses.csv')\n",
        "rlaif_data_filepath = os.path.join(datasets_folder, f'rlaif_data.csv')\n",
        "rlhf_data_filepath = os.path.join(datasets_folder, f'rlhf_data.csv')\n",
        "chat_history_filepath = os.path.join(datasets_folder, f'chat_history.csv')\n",
        "\n",
        "groq_api_key = os.getenv('GROQ_API_KEY')\n",
        "small_model = os.getenv('FINETUNE_MODEL_NAME')\n",
        "\n",
        "if not groq_api_key and 'google.colab' in sys.modules:\n",
        "\tfrom google.colab import userdata\n",
        "\tgroq_api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "if not groq_api_key:\n",
        "\traise ValueError('GROQ_API_KEY is not set in the environment variables')\n",
        "\n",
        "if os.path.exists(chat_history_filepath):\n",
        "\tchat_history = pd.read_csv(chat_history_filepath)\n",
        "else:\n",
        "\tchat_history = pd.DataFrame(columns=['query', 'response', 'timestamp'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F06mXO-e1DoB"
      },
      "source": [
        "### Generate synthetic data for fine-tuning\n",
        "**Data generation using an LLM**: Uses a Large model like Llama-3 (70B) to generate data to use for fine-tuning a small model like Phi 3 (3.8B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data size: 54\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                              output  \n",
              "0  To track your order, please visit our website ...  \n",
              "1  No problem! To reset your password, click on t...  \n",
              "2  Sorry to hear that you need to return an item....  \n",
              "3  Our standard shipping time is 3-5 business day...  \n",
              "4  Please contact us immediately if you need to c...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "def ask_larger_llm(prompt, return_quoted=True):\n",
        "\tchat_completion = client.chat.completions.create(\n",
        "\t\tmessages=[{ 'role': 'user', 'content': prompt }],\n",
        "\t\tmodel=os.getenv('GROQ_LARGE_MODEL'),\n",
        "\t)\n",
        "\tresponse = chat_completion.choices[0].message.content\n",
        "\tif not response:\n",
        "\t\traise SystemExit('No response from the API.')\n",
        "\n",
        "\tif not return_quoted:\n",
        "\t\treturn response\n",
        "\n",
        "\t# if response doesnt end with ``` then add it\n",
        "\tif not response.endswith('```'):\n",
        "\t\tresponse += '```'\n",
        "\n",
        "\t# get the data from the response - csv text between triple quotes ``` ```\n",
        "\tmatch = re.search(r'```(.*?)```', response, re.DOTALL)\n",
        "\tif match:\n",
        "\t\tquoted_text = match.group(1)\n",
        "\t\tquoted_text = quoted_text.strip()\n",
        "\n",
        "\t\t# sometimes, quotes or special characters are used to start and end the text. remove them\n",
        "\t\t# if quoted_text[0] == quoted_text[-1]:\n",
        "\t\t# \tquoted_text = quoted_text[1:-1]\n",
        "\t\t# remove only if first line doesnt end with same character\n",
        "\t\tfirst_line_end_character = quoted_text.split('\\n')[0][-1] if '\\n' in quoted_text else None\n",
        "\t\tif quoted_text[0] == quoted_text[-1] and quoted_text[0] != first_line_end_character:\n",
        "\t\t\tquoted_text = quoted_text[1:-1]\n",
        "\n",
        "\t\treturn quoted_text\n",
        "\telse:\n",
        "\t\tprint(response)\n",
        "\t\traise SystemExit('No data found in the response.')\n",
        "\n",
        "\n",
        "# if file exists, read it\n",
        "if os.path.exists(finetune_data_filepath):\n",
        "\twith open(finetune_data_filepath, 'r') as file:\n",
        "\t\tcsv_text = file.read()\n",
        "else:\n",
        "\tnum_lines = 100\n",
        "\tllm_training_data_prompt = f'Generate high-quality data for fine-tuning in csv for {topic} chatbot' \\\n",
        "\t\t\tf' for an ecommerce platform in at least {num_lines} lines of data. ' \\\n",
        "\t\t\t'Include the csv file text in triple quotes ```. ' \\\n",
        "\t\t\t'response should include no other text. fields: instruction, output.'\n",
        "\tcsv_text = ask_larger_llm(llm_training_data_prompt)\n",
        "\twith open(finetune_data_filepath, 'w') as file:\n",
        "\t\tfile.write(csv_text)\n",
        "\n",
        "\n",
        "training_data = pd.read_csv(finetune_data_filepath)\n",
        "print(f'Data size: {len(training_data)}')\n",
        "\n",
        "training_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmqi8x9d1DoC"
      },
      "source": [
        "### Prepare the model for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "YEpYrg7f1DoC",
        "outputId": "1a999437-b74e-4e92-fe23-37aa33ac3e0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: You passed in `unsloth/Phi-3-mini-4k-instruct` and `load_in_4bit = True`.\n",
            "We shall load `unsloth/Phi-3-mini-4k-instruct-bnb-4bit` for 4x faster loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
            "   \\\\   /|    GPU: NVIDIA GeForce RTX 3050 Laptop GPU. Max memory: 3.804 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: unsloth/Phi-3-mini-4k-instruct-bnb-4bit has no tokenizer.model file.\n",
            "Just informing you about this - this is not a critical error.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = 2048\n",
        "model = None\n",
        "tokenizer = None\n",
        "restored_finetuned_model = False\n",
        "device = 'cuda'  # 'cuda' or 'cpu'\n",
        "\n",
        "if os.path.exists(model_checkpoint_path):\n",
        "    try:\n",
        "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_checkpoint_path, trust_remote_code=True,\n",
        "            dtype=None, load_in_4bit = True, device_map=device,\n",
        "        )\n",
        "        restored_finetuned_model = True\n",
        "        print('Model loaded successfully.')\n",
        "    except Exception as e:\n",
        "        print('Error loading the model. Will train a new model.')\n",
        "        print(e)\n",
        "\n",
        "else:  # if not restored_finetuned_model:\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "\t\tmodel_name = small_model,\n",
        "\t\tmax_seq_length = max_seq_length,\n",
        "\t\tdtype = None,  # None for auto-detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "\t\tload_in_4bit = True,  # 4-bit quantization to reduce memory usage\n",
        "\t)\n",
        "\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "\t\tmodel,\n",
        "\t\tr = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "\t\ttarget_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj',\n",
        "\t\t\t\t\t\t'gate_proj', 'up_proj', 'down_proj',],\n",
        "\t\tlora_alpha = 16,\n",
        "\t\tlora_dropout = 0,  # Supports any, but = 0 is optimized\n",
        "\t\tbias = 'none',  # Supports any, but = 'none' is optimized\n",
        "\t\t# 'unsloth' uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "\t\tuse_gradient_checkpointing = 'unsloth', # True or 'unsloth' for very long context\n",
        "\t\tRANDOM_STATE = RANDOM_STATE,\n",
        "\t\tuse_rslora = False,\n",
        "\t\tloftq_config = None,\n",
        "\t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR_MEXIHGV6d"
      },
      "source": [
        "### Prepare the dataset for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3dSoURKgGgnN"
      },
      "outputs": [],
      "source": [
        "finetune_prompt = '''You are a customer support chatbot.\n",
        "Below is an instruction that describes a task that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Learn from the sample instruction and sample response provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}'''\n",
        "\n",
        "def create_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\toutputs = training_data['output']\n",
        "\ttexts = []\n",
        "\tfor instruction, output in zip(instructions, outputs):\n",
        "\t\t# without EOS_TOKEN, generation will go on forever\n",
        "\t\ttext = finetune_prompt.format(instruction, output) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT8lV4-IGSOT"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "-gCr-uZL1DoC",
        "outputId": "3335525d-afca-436b-98bf-d3e6124f3eb7"
      },
      "outputs": [],
      "source": [
        "trainer = None\n",
        "\n",
        "def train_model(train_dataset, force_train=False):\n",
        "\tglobal trainer, model, tokenizer, restored_finetuned_model\n",
        "\n",
        "\tif not force_train and not restored_finetuned_model:  # if restoration failed\n",
        "\t\tprint('Model restoration failed. Training a new model.')\n",
        "\t\tforce_train = True\n",
        "\n",
        "\tif force_train:\n",
        "\t\ttrainer = SFTTrainer(\n",
        "\t\t\tmodel = model,\n",
        "\t\t\ttokenizer = tokenizer,\n",
        "\t\t\ttrain_dataset = train_dataset,\n",
        "\t\t\tdataset_text_field = 'text',\n",
        "\t\t\tmax_seq_length = max_seq_length,\n",
        "\t\t\tdataset_num_proc = 2,\n",
        "\t\t\tpacking = False, # Can make training 5x faster for short sequences.\n",
        "\t\t\targs = TrainingArguments(\n",
        "\t\t\t\tper_device_train_batch_size = 2,\n",
        "\t\t\t\tgradient_accumulation_steps = 4,\n",
        "\t\t\t\twarmup_steps = 5,\n",
        "\t\t\t\tmax_steps = 60,\n",
        "\t\t\t\tlearning_rate = 2e-4,\n",
        "\t\t\t\tfp16 = not torch.cuda.is_bf16_supported(),\n",
        "\t\t\t\tbf16 = torch.cuda.is_bf16_supported(),\n",
        "\t\t\t\tlogging_steps = 1,\n",
        "\t\t\t\toptim = 'adamw_8bit',\n",
        "\t\t\t\tweight_decay = 0.01,\n",
        "\t\t\t\tlr_scheduler_type = 'linear',\n",
        "\t\t\t\tseed = RANDOM_STATE,\n",
        "\t\t\t\toutput_dir = model_checkpoint_path,\n",
        "\t\t\t),\n",
        "\t\t)\n",
        "\n",
        "\t\ttrainer.train()\n",
        "\t\tmodel.save_pretrained(model_checkpoint_path)\n",
        "\t\ttokenizer.save_pretrained(model_checkpoint_path)\n",
        "\t\t# trainer.save_model(model_checkpoint_path)\n",
        "\t\t# model.save_pretrained_merged(model_checkpoint_path + '-merged', tokenizer, save_method='merged_16bit')\n",
        "\n",
        "train_model(create_dataset(training_data), force_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcMm5av_1DoC"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W-5u1umL1DoC"
      },
      "outputs": [],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "query_prompt = '''You are a customer support chatbot. Respond to this query.\n",
        "\n",
        "### Query:\n",
        "{}\n",
        "\n",
        "### Response:'''  # leave this blank for generation!\n",
        "\n",
        "\n",
        "def ask_query(query, display=False):\n",
        "\tinputs = tokenizer([\n",
        "\t\t# query\n",
        "\t\tquery_prompt.format(query)\n",
        "\t], return_tensors = 'pt').to(device)\n",
        "\n",
        "\t# # Streaming outputs\n",
        "\t# text_streamer = TextStreamer(tokenizer)\n",
        "\t# _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n",
        "\n",
        "\toutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "\toutput = ''.join(tokenizer.batch_decode(outputs))\n",
        "\n",
        "\t# find 'Response: ' and get text after that\n",
        "\tif 'Response:' in output:\n",
        "\t\toutput = output[output.find('Response:') + len('Response:'):]\n",
        "\tif '<|assistant|>' in output:\n",
        "\t\toutput = output[output.find('<|assistant|>') + len('<|assistant|>'):]\n",
        "\tif '[Response]:' in output:\n",
        "\t\toutput = output[output.find('[Response]:') + len('[Response]:'):]\n",
        "\n",
        "\t# remove '<|endoftext|>' from end\n",
        "\tif output.endswith('<|endoftext|>'):\n",
        "\t\toutput = output[:-len('<|endoftext|>')]\n",
        "\n",
        "\toutput = output.strip()\n",
        "\n",
        "\tchat_history.loc[len(chat_history)] = [query, output, pd.Timestamp.now()]\n",
        "\tchat_history.to_csv(chat_history_filepath, index=False)\n",
        "\n",
        "\tif display:\n",
        "\t\tdisplay_md(output)\n",
        "\telse:\n",
        "\t\treturn output\n",
        "\n",
        "if HOSTING_ENABLED:\n",
        "\timport gradio as gr\n",
        "\tdef get_bot_response(query):\n",
        "\t\treturn ask_query(query)\n",
        "\tinterface=gr.Interface(\n",
        "\t\tfn=get_bot_response,\n",
        "\t\tinputs=gr.Textbox(\n",
        "\t\t\tlines=2, placeholder=\"Enter query here\",\n",
        "\t\t\tlabel=\"Query\"\n",
        "\t\t),\n",
        "\t\toutputs=gr.Textbox(label=\"Response\", lines=4),\n",
        "\t\tallow_flagging=False,\n",
        "\t)\n",
        "\tinterface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMPORTANT: You are using gradio version 4.26.0, however version 4.29.0 is available, please upgrade.\n",
            "--------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "We accept payments via credit/debit cards, PayPal, and bank transfers. Please contact us if you have any questions about payment options."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('What are the payment options?', display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "We accept the following methods of payment:\n",
              "- Credit/Debit Cards\n",
              "- PayPal\n",
              "- Bank Transfer\n",
              "- Apple Pay\n",
              "- Google Pay\n",
              "\n",
              "Please note that we may not accept certain payment methods in the future."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('List down the available methods of payment.', display=True)  # rephrasing same question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ho4XhfBmNUgb",
        "outputId": "080f5e8e-77c9-4440-d9e0-f2536202c302"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Our return policy allows for returns within [time frame]. Please see our full return policy for details."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('May I know the return policy?', display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## For more projects, open [README.md](/README.md)\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unused parts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RLAIF: Reinforcement Learning from AI (LLM) Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate responses for the questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 1/54\n",
            "Processing row 11/54\n",
            "Processing row 21/54\n",
            "Processing row 31/54\n",
            "Processing row 41/54\n",
            "Processing row 51/54\n",
            "Data size: 54\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>expected_output</th>\n",
              "      <th>current_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "      <td>Hello! I'd be happy to help you track your ord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "      <td>Absolutely, I can help you reset your password...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "      <td>I'd be happy to assist you with the return pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "      <td>I'd be happy to help you with that! The shippi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "      <td>Certainly! To assist you with canceling your o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                     expected_output  \\\n",
              "0  To track your order, please visit our website ...   \n",
              "1  No problem! To reset your password, click on t...   \n",
              "2  Sorry to hear that you need to return an item....   \n",
              "3  Our standard shipping time is 3-5 business day...   \n",
              "4  Please contact us immediately if you need to c...   \n",
              "\n",
              "                                      current_output  \n",
              "0  Hello! I'd be happy to help you track your ord...  \n",
              "1  Absolutely, I can help you reset your password...  \n",
              "2  I'd be happy to assist you with the return pro...  \n",
              "3  I'd be happy to help you with that! The shippi...  \n",
              "4  Certainly! To assist you with canceling your o...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def already_processed(df, column_name):\n",
        "\treturn column_name in df.columns and df[column_name].notnull().all()\n",
        "\n",
        "forced_queries = False  # temp\n",
        "\n",
        "if not forced_queries and os.path.exists(all_query_responses_filepath):\n",
        "\tall_query_responses = pd.read_csv(all_query_responses_filepath)\n",
        "else:\n",
        "\t# provide expected response and current response to AI, ask to improve the response, fine-tune the model again\n",
        "\tall_query_responses = training_data.copy()\n",
        "\t# rename output to expected_output\n",
        "\tall_query_responses.rename(columns={ 'output': 'expected_output' }, inplace = True)\n",
        "\tall_query_responses['current_output'] = None\n",
        "\n",
        "\t# generate response with ask_query function\n",
        "\t# no parallel processing due to CPU heat concerns\n",
        "\tfor row_num, row in all_query_responses.iterrows():\n",
        "\t\tif row_num % 10 == 0:\n",
        "\t\t\tprint(f'Processing row {row_num+1}/{len(all_query_responses)}')\n",
        "\t\tcurrent_output = all_query_responses.at[row_num, 'current_output']\n",
        "\t\tif not current_output:\n",
        "\t\t\tresponse = ask_query(row['instruction'])\n",
        "\t\t\tall_query_responses.at[row_num, 'current_output'] = response\n",
        "\n",
        "\tall_query_responses.to_csv(all_query_responses_filepath, index=False)\n",
        "\n",
        "print('Data size:', len(all_query_responses))\n",
        "all_query_responses.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get feedback from a larger LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data size: 53\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>expected_output</th>\n",
              "      <th>current_output</th>\n",
              "      <th>improved_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "      <td>To track your order, please log into your acco...</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "      <td>I'm sorry, but I'm unable to assist with reset...</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "      <td>** To return an item, you typically need to fo...</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "      <td>The shipping time for your order depends on th...</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "      <td>I'm sorry, but once an order is shipped, we're...</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                     expected_output  \\\n",
              "0  To track your order, please visit our website ...   \n",
              "1  No problem! To reset your password, click on t...   \n",
              "2  Sorry to hear that you need to return an item....   \n",
              "3  Our standard shipping time is 3-5 business day...   \n",
              "4  Please contact us immediately if you need to c...   \n",
              "\n",
              "                                      current_output  \\\n",
              "0  To track your order, please log into your acco...   \n",
              "1  I'm sorry, but I'm unable to assist with reset...   \n",
              "2  ** To return an item, you typically need to fo...   \n",
              "3  The shipping time for your order depends on th...   \n",
              "4  I'm sorry, but once an order is shipped, we're...   \n",
              "\n",
              "                                     improved_output  \n",
              "0  To track your order, please visit our website ...  \n",
              "1  No problem! To reset your password, click on t...  \n",
              "2  Sorry to hear that you need to return an item....  \n",
              "3  Our standard shipping time is 3-5 business day...  \n",
              "4  Please contact us immediately if you need to c...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forced_rlaif = False  # temp\n",
        "\n",
        "if os.path.exists(rlaif_data_filepath):\n",
        "\trlaif_data = pd.read_csv(rlaif_data_filepath)\n",
        "\tif forced_rlaif:\n",
        "\t\trlaif_data['improved_output'] = None  # set to None\n",
        "else:\n",
        "\trlaif_data = all_query_responses.copy()\n",
        "\trlaif_data['improved_output'] = None  # add column\n",
        "\n",
        "# if column is not loaded from file, or empty\n",
        "if not already_processed(rlaif_data, 'improved_output'):\n",
        "\trlaif_llm_prompt = '''\n",
        "\t\tI am fine-tuning a customer-support chatbot. \n",
        "\t\tI provided the instruction, current_output, expected_output (provided by you in the past). \n",
        "\t\tInclude csv text in the response in triple quotes ```.\n",
        "\t\treturn only these headers: instruction, improved_output. \n",
        "\t'''\n",
        "\n",
        "\t# pass 15 rows at a time to the AI to improve the response\n",
        "\tfor row_num in range(0, len(rlaif_data), 15):\n",
        "\t\tprint(f'Processing rows {row_num} to {row_num+15} of {len(rlaif_data)} rows')\n",
        "\t\tchunk = rlaif_data.iloc[row_num:row_num+15]\n",
        "\t\tcsv_text = chunk.to_csv(index=False)\n",
        "\t\tresponse_csv = ask_larger_llm(f'{rlaif_llm_prompt}\\n```{csv_text}```')\n",
        "\t\ttry:\n",
        "\t\t\tresponse_data = pd.read_csv(StringIO(response_csv))\n",
        "\t\texcept:\n",
        "\t\t\tprint('Failed to parse csv data from the response.')\n",
        "\t\t\tprint(response_csv)\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\t# for each row's instruction value in response_data, update the corresponding row in rlaif_improved\n",
        "\t\tfor index, row in response_data.iterrows():\n",
        "\t\t\tif 'instruction' not in row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tinstruction = row['instruction']\n",
        "\t\t\timproved_output = row['improved_output']\n",
        "\t\t\tif 'no improvement' in improved_output.lower():\n",
        "\t\t\t\timproved_output = None\n",
        "\t\t\tif improved_output is not None: # and current_output != improved_output:\n",
        "\t\t\t\tinstruction_row = rlaif_data[rlaif_data['instruction'] == instruction]\n",
        "\t\t\t\tcurrent_output = instruction_row['current_output'].values[0]\n",
        "\t\t\t\tif current_output != improved_output:\n",
        "\t\t\t\t\trlaif_data.loc[rlaif_data['instruction'] == instruction, 'improved_output'] = improved_output\n",
        "\n",
        "\trlaif_data.dropna(subset=['improved_output'], inplace=True)\n",
        "\trlaif_data.to_csv(rlaif_data_filepath, index=False)\n",
        "\n",
        "print('Data size:', len(rlaif_data))\n",
        "rlaif_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fine-tuning using the RLAIF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "rlaif_prompt = '''You are a customer support chatbot.\n",
        "I listed improvements from human feedback.\n",
        "Learn from the sample instruction, current response, and improved response provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Current Response:\n",
        "{}\n",
        "\n",
        "### Improved response:\n",
        "{}'''\n",
        "\n",
        "def create_rlaif_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\tcurrent_outputs = training_data['current_output']\n",
        "\timproved_outputs = training_data['improved_output']\n",
        "\ttexts = []\n",
        "\tfor instruction, current_output, improved_output in zip(instructions, current_outputs, improved_outputs):\n",
        "\t\ttext = rlaif_prompt.format(instruction, current_output, improved_output) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset\n",
        "\n",
        "train_model(create_rlaif_dataset(rlaif_data), force_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RLHF: Reinforcement Learning from Human Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Emulating human feedback with a larger LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "      <th>like_dislike_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>You can track your order by logging into your ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>To return an item, please visit our website an...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Yes, you can cancel your order within 24 hours...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want to change my shipping address. Can you ...</td>\n",
              "      <td>I'd be happy to help you update your shipping ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I want to know more about your products.</td>\n",
              "      <td>We offer a wide range of products in various c...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         instruction  \\\n",
              "0                      Hi, I want to track my order.   \n",
              "1      I want to return an item. What's the process?   \n",
              "2                             Can I cancel my order?   \n",
              "3  I want to change my shipping address. Can you ...   \n",
              "4           I want to know more about your products.   \n",
              "\n",
              "                                              output  like_dislike_status  \n",
              "0  You can track your order by logging into your ...                 True  \n",
              "1  To return an item, please visit our website an...                False  \n",
              "2  Yes, you can cancel your order within 24 hours...                 True  \n",
              "3  I'd be happy to help you update your shipping ...                 True  \n",
              "4  We offer a wide range of products in various c...                False  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forced_rlhf = False\n",
        "\n",
        "if os.path.exists(rlhf_data_filepath):\n",
        "\trlhf_data = pd.read_csv(rlhf_data_filepath)\n",
        "\tif forced_rlhf:\n",
        "\t\trlhf_data['like_dislike_status'] = None  # set to None\n",
        "else:\n",
        "\trlhf_data = all_query_responses.copy()\n",
        "\trlhf_data['like_dislike_status'] = None  # add column\n",
        "\n",
        "if not already_processed(rlhf_data, 'like_dislike_status'):\n",
        "\trlhf_llm_prompt = '''\n",
        "\t\tI am emulating RLHF (human feedback) for a customer-support chatbot.\n",
        "\t\tI provided the \"instruction\" column.\n",
        "\t\tSelect random instructions and provide a \"like_dislike_status\" value (True or False).\n",
        "\t\tSame instruction can be repeated with different output and like_dislike_status values. Some instructions can be skipped.\n",
        "\t\treturn only these headers: instruction, output, like_dislike_status.\n",
        "\t\tInclude csv text in the response in triple quotes ```.\n",
        "\t'''\n",
        "\tcsv_text = rlhf_data[['instruction']].to_csv(index=False)\n",
        "\tresponse_csv = ask_larger_llm(f'{rlhf_llm_prompt}\\n```{csv_text}```')\n",
        "\ttry:\n",
        "\t\trlhf_data = pd.read_csv(StringIO(response_csv))\n",
        "\texcept:\n",
        "\t\tprint('Failed to parse csv data from the response:')\n",
        "\t\tprint(response_csv)\n",
        "\trlhf_data.to_csv(rlhf_data_filepath, index=False)\n",
        "\n",
        "rlhf_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fine-tuning using the RLHF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "rlhf_prompt = '''You are a customer support chatbot.\n",
        "I listed improvements from human feedback.\n",
        "Learn from the sample instruction, current response, and Like/Dislike status provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Current Response:\n",
        "{}\n",
        "\n",
        "### User Like/Dislike Status:\n",
        "{}'''\n",
        "\n",
        "def create_rlhf_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\toutputs = training_data['output']\n",
        "\tlike_dislike_statuses = training_data['like_dislike_status']\n",
        "\ttexts = []\n",
        "\tfor instruction, output, like_dislike_status in zip(instructions, outputs, like_dislike_statuses):\n",
        "\t\ttext = rlhf_prompt.format(instruction, output, like_dislike_status) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset\n",
        "\n",
        "train_model(create_rlhf_dataset(rlhf_data), force_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Responsible AI monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Here is the table with the responses that require comments:\n",
              "\n",
              "| Output | Comment |\n",
              "| --- | --- |\n",
              "| `<s> I'd like to place an order over the phone. ...` | The chatbot seems to be confused about the context of the conversation and is trying to interpret a statement about placing an order over the phone as a conversation about ordering a pizza. |\n",
              "| `<s> I'm having trouble checking out. ...` | The chatbot appears to be mistakenly interpreting a Git command as a checkout issue in an e-commerce context. |\n",
              "| `<s> I'm trying to check the status of my order. ...` | The chatbot is responding to a repeated question about checking the status of an order with a canned response, rather than attempting to assist the customer with their issue. |\n",
              "| `<s> I'm having trouble logging in. ...` | The chatbot is providing an unhelpful response to a login issue, asking the customer to provide more information without attempting to troubleshoot the problem. |\n",
              "| `<s> I'd like to cancel my subscription. ...` | The chatbot is providing an unhelpful response to a subscription cancellation issue, asking the customer to contact support without attempting to assist with the cancellation. |\n",
              "| `<s> I'm experiencing issues with the website. ...` | The chatbot is responding to a website issue with a canned response, asking the customer to contact support without attempting to troubleshoot the problem. |\n",
              "| `<s> I'm trying to redeem a promo code. ...` | The chatbot is mistakenly interpreting a promo code redemption issue as a Scala programming issue. |\n",
              "| `<s> I'm having trouble with my email subscription. ...` | The chatbot is responding to an email subscription issue with a canned response, asking the customer to try again later without attempting to assist with the problem. |\n",
              "| `<s> I'm experiencing issues with checkout. ...` | The chatbot is responding to a checkout issue with a canned response, asking the customer to search for the item rather than attempting to assist with the problem. |\n",
              "| `<s> I'm having trouble with my order history. ...` | The chatbot is responding to an order history issue with a canned response, asking the customer to contact support without attempting to assist with the problem. |\n",
              "| `<s> I'd like to update my payment method. ...` | The chatbot is responding to a payment method update issue with a canned response, asking the customer to use the API documentation without attempting to assist with the problem. |\n",
              "| `<s> I'm experiencing issues with my account. ...` | The chatbot is responding to an account issue with a canned response, asking the customer to contact support without attempting to assist with the problem. |\n",
              "| `<s> I'd like to track my reward points. ...` | The chatbot is mistakenly interpreting a reward points tracking issue as a Java programming issue. |\n",
              "| `<s> I'm having trouble logging out. ...` | The chatbot is responding to a logout issue with a canned response, asking the customer to try again later without attempting to assist with the problem. |\n",
              "\n",
              "These responses indicate that the chatbot may not be adequately trained to handle certain scenarios, leading to unhelpful or confusing responses."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "resai_prompt = '''\n",
        "\tYou are a Ethical AI and ResAI (Responsible AI) reviewer.\n",
        "\tI am sending the response (output column) from a customer support chatbot.\n",
        "\tIf any response is inappropriate, mention that response and your comment.\n",
        "\tDisplay like a table with output and your comment.\n",
        "\tInclude the row only if you have a comment.\n",
        "'''\n",
        "\n",
        "resai_data = all_query_responses.drop(['instruction', 'expected_output'], axis=1).copy()  # exclude without removing\n",
        "csv_text = resai_data.to_csv(index=False)\n",
        "response = ask_larger_llm(f'{resai_prompt}\\n```{csv_text}```', return_quoted=False)\n",
        "response = re.sub(r'^.*\\(OK\\)', '', response, flags=re.MULTILINE)  # remove lines that end with (OK)\n",
        "display_md(response)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
