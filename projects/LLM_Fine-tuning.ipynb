{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href='https://colab.research.google.com/github/prane-eth/AI_projects/blob/main/projects/LLM_fine-tuning.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUnsdLr1Dn-"
      },
      "source": [
        "### Project: Fine-tuning a language model\n",
        "\n",
        "Demo:\n",
        "![LLMs - Finetuning, RLAIF, and RLHF](../Demo/LLM_Fine-tuning.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aGqbJDNf1DoA"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    __import__('unsloth')\n",
        "except ImportError:\n",
        "\t# %%capture\n",
        "\t%pip install pandas groq python-dotenv datasets\n",
        "\t%pip install 'unsloth @ git+https://github.com/unslothai/unsloth.git'\n",
        "\t%pip install --no-deps 'xformers<0.0.26' trl tyro peft accelerate bitsandbytes\n",
        "\t%pip install torch==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "from datasets import Dataset\n",
        "from groq import Groq\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import TrainingArguments, set_seed\n",
        "from trl import SFTTrainer\n",
        "from unsloth import FastLanguageModel\n",
        "from common_functions import display_md\n",
        "\n",
        "HOSTING_ENABLED = True\n",
        "\n",
        "random_state = 42\n",
        "set_seed(random_state)\n",
        "\n",
        "datasets_folder = 'datasets'\n",
        "if not os.path.exists(datasets_folder):\n",
        "\tos.makedirs(datasets_folder)\n",
        "\n",
        "topic = 'customer_support'\n",
        "datasets_folder = os.path.join(datasets_folder, topic + '_bot')  # create sub-folder for the topic\n",
        "if not os.path.exists(datasets_folder):\n",
        "\tos.makedirs(datasets_folder)\n",
        "\n",
        "finetune_data_filepath = os.path.join(datasets_folder, f'{topic}_bot_finetune_data.csv')\n",
        "model_checkpoint_path = os.path.join(datasets_folder, f'{topic}_saved_model')\n",
        "all_query_responses_filepath = os.path.join(datasets_folder, f'{topic}_bot_all_query_responses.csv')\n",
        "rlaif_data_filepath = os.path.join(datasets_folder, f'{topic}_bot_rlaif_data.csv')\n",
        "rlhf_data_filepath = os.path.join(datasets_folder, f'{topic}_bot_rlhf_data.csv')\n",
        "chat_history_filepath = os.path.join(datasets_folder, f'{topic}_bot_chat_history.csv')\n",
        "\n",
        "groq_api_key = os.getenv('GROQ_API_KEY')\n",
        "\n",
        "if not groq_api_key and 'google.colab' in sys.modules:\n",
        "\tfrom google.colab import userdata\n",
        "\tgroq_api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "if not groq_api_key:\n",
        "\traise ValueError('GROQ_API_KEY is not set in the environment variables')\n",
        "\n",
        "if os.path.exists(chat_history_filepath):\n",
        "\tchat_history = pd.read_csv(chat_history_filepath)\n",
        "else:\n",
        "\tchat_history = pd.DataFrame(columns=['query', 'response', 'timestamp'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F06mXO-e1DoB"
      },
      "source": [
        "### Generate synthetic data for fine-tuning\n",
        "**Data generation using an LLM**: Uses a Large model like Llama-3 (70B) to generate data to use for fine-tuning a small model like Phi 3 (3.8B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data size: 54\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                              output  \n",
              "0  To track your order, please visit our website ...  \n",
              "1  No problem! To reset your password, click on t...  \n",
              "2  Sorry to hear that you need to return an item....  \n",
              "3  Our standard shipping time is 3-5 business day...  \n",
              "4  Please contact us immediately if you need to c...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "def ask_larger_llm(prompt, model='llama3-70b-8192', return_quoted=True):\n",
        "\tchat_completion = client.chat.completions.create(\n",
        "\t\tmessages=[{ 'role': 'user', 'content': prompt }],\n",
        "\t\tmodel=model,\n",
        "\t)\n",
        "\tresponse = chat_completion.choices[0].message.content\n",
        "\tif not response:\n",
        "\t\traise SystemExit('No response from the API.')\n",
        "\n",
        "\tif not return_quoted:\n",
        "\t\treturn response\n",
        "\n",
        "\t# if response doesnt end with ``` then add it\n",
        "\tif not response.endswith('```'):\n",
        "\t\tresponse += '```'\n",
        "\n",
        "\t# get the data from the response - csv text between triple quotes ``` ```\n",
        "\tmatch = re.search(r'```(.*?)```', response, re.DOTALL)\n",
        "\tif match:\n",
        "\t\tquoted_text = match.group(1)\n",
        "\t\tquoted_text = quoted_text.strip()\n",
        "\n",
        "\t\t# sometimes, quotes or special characters are used to start and end the text. remove them\n",
        "\t\t# if quoted_text[0] == quoted_text[-1]:\n",
        "\t\t# \tquoted_text = quoted_text[1:-1]\n",
        "\t\t# remove only if first line doesnt end with same character\n",
        "\t\tfirst_line_end_character = quoted_text.split('\\n')[0][-1] if '\\n' in quoted_text else None\n",
        "\t\tif quoted_text[0] == quoted_text[-1] and quoted_text[0] != first_line_end_character:\n",
        "\t\t\tquoted_text = quoted_text[1:-1]\n",
        "\n",
        "\t\treturn quoted_text\n",
        "\telse:\n",
        "\t\tprint(response)\n",
        "\t\traise SystemExit('No data found in the response.')\n",
        "\n",
        "\n",
        "# if file exists, read it\n",
        "if os.path.exists(finetune_data_filepath):\n",
        "\twith open(finetune_data_filepath, 'r') as file:\n",
        "\t\tcsv_text = file.read()\n",
        "else:\n",
        "\tnum_lines = 100\n",
        "\tprompt = f'Generate high-quality data for fine-tuning in csv for {topic} chatbot' \\\n",
        "\t\t\tf' for an ecommerce platform in at least {num_lines} lines of data. ' \\\n",
        "\t\t\t'Include the csv file text in triple quotes ```. ' \\\n",
        "\t\t\t'response should include no other text. fields: instruction, output.'\n",
        "\tcsv_text = ask_larger_llm(prompt)\n",
        "\twith open(finetune_data_filepath, 'w') as file:\n",
        "\t\tfile.write(csv_text)\n",
        "\n",
        "\n",
        "training_data = pd.read_csv(finetune_data_filepath)\n",
        "print(f'Data size: {len(training_data)}')\n",
        "\n",
        "training_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmqi8x9d1DoC"
      },
      "source": [
        "### Prepare the model for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "YEpYrg7f1DoC",
        "outputId": "1a999437-b74e-4e92-fe23-37aa33ac3e0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: You passed in `unsloth/Phi-3-mini-4k-instruct` and `load_in_4bit = True`.\n",
            "We shall load `unsloth/Phi-3-mini-4k-instruct-bnb-4bit` for 4x faster loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
            "   \\\\   /|    GPU: NVIDIA GeForce RTX 3050 Laptop GPU. Max memory: 3.804 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: unsloth/Phi-3-mini-4k-instruct-bnb-4bit has no tokenizer.model file.\n",
            "Just informing you about this - this is not a critical error.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = 2048\n",
        "model = None\n",
        "tokenizer = None\n",
        "restored_finetuned_model = False\n",
        "device = 'cuda'  # 'cuda' or 'cpu'\n",
        "\n",
        "if os.path.exists(model_checkpoint_path):\n",
        "    try:\n",
        "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_checkpoint_path, trust_remote_code=True,\n",
        "            dtype=None, load_in_4bit = True, device_map=device,\n",
        "        )\n",
        "        restored_finetuned_model = True\n",
        "        print('Model loaded successfully.')\n",
        "    except Exception as e:\n",
        "        print('Error loading the model. Will train a new model.')\n",
        "        print(e)\n",
        "else:  # if not restored_finetuned_model:\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "\t\tmodel_name = 'unsloth/Phi-3-mini-4k-instruct',\n",
        "\t\tmax_seq_length = max_seq_length,\n",
        "\t\tdtype = None,  # None for auto-detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "\t\tload_in_4bit = True,  # 4-bit quantization to reduce memory usage\n",
        "\t)\n",
        "\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "\t\tmodel,\n",
        "\t\tr = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "\t\ttarget_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj',\n",
        "\t\t\t\t\t\t'gate_proj', 'up_proj', 'down_proj',],\n",
        "\t\tlora_alpha = 16,\n",
        "\t\tlora_dropout = 0,  # Supports any, but = 0 is optimized\n",
        "\t\tbias = 'none',  # Supports any, but = 'none' is optimized\n",
        "\t\t# 'unsloth' uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "\t\tuse_gradient_checkpointing = 'unsloth', # True or 'unsloth' for very long context\n",
        "\t\trandom_state = random_state,\n",
        "\t\tuse_rslora = False,\n",
        "\t\tloftq_config = None,\n",
        "\t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR_MEXIHGV6d"
      },
      "source": [
        "### Prepare the dataset for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3dSoURKgGgnN"
      },
      "outputs": [],
      "source": [
        "finetune_prompt = '''You are a customer support chatbot.\n",
        "Below is an instruction that describes a task that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Learn from the sample instruction and sample response provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}'''\n",
        "\n",
        "def create_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\toutputs = training_data['output']\n",
        "\ttexts = []\n",
        "\tfor instruction, output in zip(instructions, outputs):\n",
        "\t\t# without EOS_TOKEN, generation will go on forever\n",
        "\t\ttext = finetune_prompt.format(instruction, output) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT8lV4-IGSOT"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "-gCr-uZL1DoC",
        "outputId": "3335525d-afca-436b-98bf-d3e6124f3eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model not found. Training from scratch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1506c1a0189647e7b1a3334061a93dc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/54 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 54 | Num Epochs = 10\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 60\n",
            " \"-____-\"     Number of trainable parameters = 29,884,416\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45addce405a94bc784237671dfe4b132",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.2197, 'grad_norm': 5.195870399475098, 'learning_rate': 4e-05, 'epoch': 0.15}\n",
            "{'loss': 3.1891, 'grad_norm': 5.157214641571045, 'learning_rate': 8e-05, 'epoch': 0.3}\n",
            "{'loss': 3.0942, 'grad_norm': 4.931565761566162, 'learning_rate': 0.00012, 'epoch': 0.44}\n",
            "{'loss': 2.99, 'grad_norm': 4.9368767738342285, 'learning_rate': 0.00016, 'epoch': 0.59}\n",
            "{'loss': 2.3223, 'grad_norm': 3.631701707839966, 'learning_rate': 0.0002, 'epoch': 0.74}\n",
            "{'loss': 1.7856, 'grad_norm': 2.5708842277526855, 'learning_rate': 0.00019636363636363636, 'epoch': 0.89}\n",
            "{'loss': 1.4676, 'grad_norm': 2.2668449878692627, 'learning_rate': 0.00019272727272727274, 'epoch': 1.04}\n",
            "{'loss': 1.2452, 'grad_norm': 1.818638563156128, 'learning_rate': 0.0001890909090909091, 'epoch': 1.19}\n",
            "{'loss': 0.9675, 'grad_norm': 1.2796220779418945, 'learning_rate': 0.00018545454545454545, 'epoch': 1.33}\n",
            "{'loss': 0.7824, 'grad_norm': 1.2415987253189087, 'learning_rate': 0.00018181818181818183, 'epoch': 1.48}\n",
            "{'loss': 0.6052, 'grad_norm': 0.9284795522689819, 'learning_rate': 0.0001781818181818182, 'epoch': 1.63}\n",
            "{'loss': 0.568, 'grad_norm': 0.5942176580429077, 'learning_rate': 0.00017454545454545454, 'epoch': 1.78}\n",
            "{'loss': 0.5005, 'grad_norm': 0.40140464901924133, 'learning_rate': 0.0001709090909090909, 'epoch': 1.93}\n",
            "{'loss': 0.5373, 'grad_norm': 0.4086431562900543, 'learning_rate': 0.00016727272727272728, 'epoch': 2.07}\n",
            "{'loss': 0.5405, 'grad_norm': 0.4129643440246582, 'learning_rate': 0.00016363636363636366, 'epoch': 2.22}\n",
            "{'loss': 0.4699, 'grad_norm': 0.5641664862632751, 'learning_rate': 0.00016, 'epoch': 2.37}\n",
            "{'loss': 0.4654, 'grad_norm': 0.4246687889099121, 'learning_rate': 0.00015636363636363637, 'epoch': 2.52}\n",
            "{'loss': 0.3876, 'grad_norm': 0.5355654358863831, 'learning_rate': 0.00015272727272727275, 'epoch': 2.67}\n",
            "{'loss': 0.4119, 'grad_norm': 0.514842689037323, 'learning_rate': 0.0001490909090909091, 'epoch': 2.81}\n",
            "{'loss': 0.3862, 'grad_norm': 0.5212636590003967, 'learning_rate': 0.00014545454545454546, 'epoch': 2.96}\n",
            "{'loss': 0.368, 'grad_norm': 0.5720509886741638, 'learning_rate': 0.00014181818181818184, 'epoch': 3.11}\n",
            "{'loss': 0.3381, 'grad_norm': 0.5990394353866577, 'learning_rate': 0.0001381818181818182, 'epoch': 3.26}\n",
            "{'loss': 0.3121, 'grad_norm': 0.6918390393257141, 'learning_rate': 0.00013454545454545455, 'epoch': 3.41}\n",
            "{'loss': 0.3734, 'grad_norm': 0.7043582201004028, 'learning_rate': 0.00013090909090909093, 'epoch': 3.56}\n",
            "{'loss': 0.3206, 'grad_norm': 0.634774386882782, 'learning_rate': 0.00012727272727272728, 'epoch': 3.7}\n",
            "{'loss': 0.2996, 'grad_norm': 0.5557631254196167, 'learning_rate': 0.00012363636363636364, 'epoch': 3.85}\n",
            "{'loss': 0.3061, 'grad_norm': 0.34234341979026794, 'learning_rate': 0.00012, 'epoch': 4.0}\n",
            "{'loss': 0.263, 'grad_norm': 0.4772837460041046, 'learning_rate': 0.00011636363636363636, 'epoch': 4.15}\n",
            "{'loss': 0.277, 'grad_norm': 0.29725486040115356, 'learning_rate': 0.00011272727272727272, 'epoch': 4.3}\n",
            "{'loss': 0.2731, 'grad_norm': 0.2569822669029236, 'learning_rate': 0.00010909090909090909, 'epoch': 4.44}\n",
            "{'loss': 0.2526, 'grad_norm': 0.33668771386146545, 'learning_rate': 0.00010545454545454545, 'epoch': 4.59}\n",
            "{'loss': 0.2316, 'grad_norm': 0.28192031383514404, 'learning_rate': 0.00010181818181818181, 'epoch': 4.74}\n",
            "{'loss': 0.2549, 'grad_norm': 0.3207797408103943, 'learning_rate': 9.818181818181818e-05, 'epoch': 4.89}\n",
            "{'loss': 0.2265, 'grad_norm': 0.2725105285644531, 'learning_rate': 9.454545454545455e-05, 'epoch': 5.04}\n",
            "{'loss': 0.2401, 'grad_norm': 0.2648123502731323, 'learning_rate': 9.090909090909092e-05, 'epoch': 5.19}\n",
            "{'loss': 0.2625, 'grad_norm': 0.2734944224357605, 'learning_rate': 8.727272727272727e-05, 'epoch': 5.33}\n",
            "{'loss': 0.1991, 'grad_norm': 0.31084543466567993, 'learning_rate': 8.363636363636364e-05, 'epoch': 5.48}\n",
            "{'loss': 0.2188, 'grad_norm': 0.33300596475601196, 'learning_rate': 8e-05, 'epoch': 5.63}\n",
            "{'loss': 0.1905, 'grad_norm': 0.3082767724990845, 'learning_rate': 7.636363636363637e-05, 'epoch': 5.78}\n",
            "{'loss': 0.1928, 'grad_norm': 0.3696229159832001, 'learning_rate': 7.272727272727273e-05, 'epoch': 5.93}\n",
            "{'loss': 0.1942, 'grad_norm': 0.29888370633125305, 'learning_rate': 6.90909090909091e-05, 'epoch': 6.07}\n",
            "{'loss': 0.1995, 'grad_norm': 0.2828451693058014, 'learning_rate': 6.545454545454546e-05, 'epoch': 6.22}\n",
            "{'loss': 0.1996, 'grad_norm': 0.3153746724128723, 'learning_rate': 6.181818181818182e-05, 'epoch': 6.37}\n",
            "{'loss': 0.187, 'grad_norm': 0.2937484681606293, 'learning_rate': 5.818181818181818e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1727, 'grad_norm': 0.30278438329696655, 'learning_rate': 5.4545454545454546e-05, 'epoch': 6.67}\n",
            "{'loss': 0.1853, 'grad_norm': 0.3732646107673645, 'learning_rate': 5.090909090909091e-05, 'epoch': 6.81}\n",
            "{'loss': 0.1457, 'grad_norm': 0.2931429147720337, 'learning_rate': 4.7272727272727275e-05, 'epoch': 6.96}\n",
            "{'loss': 0.1506, 'grad_norm': 0.3012927174568176, 'learning_rate': 4.3636363636363636e-05, 'epoch': 7.11}\n",
            "{'loss': 0.1583, 'grad_norm': 0.31850045919418335, 'learning_rate': 4e-05, 'epoch': 7.26}\n",
            "{'loss': 0.192, 'grad_norm': 0.35393840074539185, 'learning_rate': 3.6363636363636364e-05, 'epoch': 7.41}\n",
            "{'loss': 0.1493, 'grad_norm': 0.3377722501754761, 'learning_rate': 3.272727272727273e-05, 'epoch': 7.56}\n",
            "{'loss': 0.1338, 'grad_norm': 0.3104094862937927, 'learning_rate': 2.909090909090909e-05, 'epoch': 7.7}\n",
            "{'loss': 0.1544, 'grad_norm': 0.3433487117290497, 'learning_rate': 2.5454545454545454e-05, 'epoch': 7.85}\n",
            "{'loss': 0.1506, 'grad_norm': 0.3721027970314026, 'learning_rate': 2.1818181818181818e-05, 'epoch': 8.0}\n",
            "{'loss': 0.1208, 'grad_norm': 0.32525575160980225, 'learning_rate': 1.8181818181818182e-05, 'epoch': 8.15}\n",
            "{'loss': 0.1845, 'grad_norm': 0.36251649260520935, 'learning_rate': 1.4545454545454545e-05, 'epoch': 8.3}\n",
            "{'loss': 0.1594, 'grad_norm': 0.3527419865131378, 'learning_rate': 1.0909090909090909e-05, 'epoch': 8.44}\n",
            "{'loss': 0.122, 'grad_norm': 0.30333641171455383, 'learning_rate': 7.272727272727272e-06, 'epoch': 8.59}\n",
            "{'loss': 0.1416, 'grad_norm': 0.3590288460254669, 'learning_rate': 3.636363636363636e-06, 'epoch': 8.74}\n",
            "{'loss': 0.1111, 'grad_norm': 0.2885575592517853, 'learning_rate': 0.0, 'epoch': 8.89}\n",
            "{'train_runtime': 229.0985, 'train_samples_per_second': 2.095, 'train_steps_per_second': 0.262, 'train_loss': 0.5758162543177605, 'epoch': 8.89}\n"
          ]
        }
      ],
      "source": [
        "trainer = None\n",
        "\n",
        "def train_model(train_dataset, force_train=False):\n",
        "\tglobal trainer, model, tokenizer, restored_finetuned_model\n",
        "\n",
        "\tif not restored_finetuned_model:  # if restoration failed\n",
        "\t\tif not os.path.exists(model_checkpoint_path):\n",
        "\t\t\tprint('Model not found. Training from scratch.')\n",
        "\t\t\tforce_train = True\n",
        "\n",
        "\tif force_train:\n",
        "\t\ttrainer = SFTTrainer(\n",
        "\t\t\tmodel = model,\n",
        "\t\t\ttokenizer = tokenizer,\n",
        "\t\t\ttrain_dataset = train_dataset,\n",
        "\t\t\tdataset_text_field = 'text',\n",
        "\t\t\tmax_seq_length = max_seq_length,\n",
        "\t\t\tdataset_num_proc = 2,\n",
        "\t\t\tpacking = False, # Can make training 5x faster for short sequences.\n",
        "\t\t\targs = TrainingArguments(\n",
        "\t\t\t\tper_device_train_batch_size = 2,\n",
        "\t\t\t\tgradient_accumulation_steps = 4,\n",
        "\t\t\t\twarmup_steps = 5,\n",
        "\t\t\t\tmax_steps = 60,\n",
        "\t\t\t\tlearning_rate = 2e-4,\n",
        "\t\t\t\tfp16 = not torch.cuda.is_bf16_supported(),\n",
        "\t\t\t\tbf16 = torch.cuda.is_bf16_supported(),\n",
        "\t\t\t\tlogging_steps = 1,\n",
        "\t\t\t\toptim = 'adamw_8bit',\n",
        "\t\t\t\tweight_decay = 0.01,\n",
        "\t\t\t\tlr_scheduler_type = 'linear',\n",
        "\t\t\t\tseed = random_state,\n",
        "\t\t\t\toutput_dir = model_checkpoint_path,\n",
        "\t\t\t),\n",
        "\t\t)\n",
        "\n",
        "\t\ttrainer.train()\n",
        "\t\tmodel.save_pretrained(model_checkpoint_path)\n",
        "\t\ttokenizer.save_pretrained(model_checkpoint_path)\n",
        "\t\t# trainer.save_model(model_checkpoint_path)\n",
        "\t\t# model.save_pretrained_merged(model_checkpoint_path + '-merged', tokenizer, save_method='merged_16bit')\n",
        "\n",
        "train_model(create_dataset(training_data), force_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcMm5av_1DoC"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W-5u1umL1DoC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/praneeth/Desktop/AI_projects/.venv/lib/python3.10/site-packages/gradio/interface.py:374: UserWarning: The `allow_flagging` parameter in `Interface` nowtakes a string value ('auto', 'manual', or 'never'), not a boolean. Setting parameter to: 'never'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "def ask_query(query, display=False):\n",
        "\tinputs = tokenizer([\n",
        "\t\tquery\n",
        "\t\t# prompt.format(\n",
        "\t\t# \tquery,\n",
        "\t\t# \t'', # output - leave this blank for generation!\n",
        "\t\t# )\n",
        "\t], return_tensors = 'pt').to(device)\n",
        "\n",
        "\t# # Streaming outputs\n",
        "\t# text_streamer = TextStreamer(tokenizer)\n",
        "\t# _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n",
        "\n",
        "\toutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "\toutput = ''.join(tokenizer.batch_decode(outputs))\n",
        "\n",
        "\t# find 'Response: ' and get text after that\n",
        "\tif 'Response:' in output:\n",
        "\t\toutput = output[output.find('Response:') + len('Response:'):]\n",
        "\n",
        "\t# if <|assistant|> is in output, get text after that\n",
        "\tif '<|assistant|>' in output:\n",
        "\t\toutput = output[output.find('<|assistant|>') + len('<|assistant|>'):]\n",
        "\n",
        "\t# if [Response]: is in output, get text after that\n",
        "\tif '[Response]:' in output:\n",
        "\t\toutput = output[output.find('[Response]:') + len('[Response]:'):]\n",
        "\n",
        "\t# remove '<|endoftext|>' from end\n",
        "\tif output.endswith('<|endoftext|>'):\n",
        "\t\toutput = output[:-len('<|endoftext|>')]\n",
        "\n",
        "\toutput = output.strip()\n",
        "\n",
        "\t# chat_history.loc[len(chat_history)] = [query, output, pd.Timestamp.now()]\n",
        "\t# chat_history.to_csv(chat_history_filepath, index=False)\n",
        "\n",
        "\tif display:\n",
        "\t\tdisplay_md(output)\n",
        "\telse:\n",
        "\t\treturn output\n",
        "\n",
        "if HOSTING_ENABLED:\n",
        "\timport gradio as gr\n",
        "\tdef get_bot_response(query):\n",
        "\t\treturn ask_query(query)\n",
        "\tinterface=gr.Interface(\n",
        "\t\tfn=get_bot_response,\n",
        "\t\tinputs=gr.Textbox(\n",
        "\t\t\tlines=2, placeholder=\"Enter query here\",\n",
        "\t\t\tlabel=\"Query\"\n",
        "\t\t),\n",
        "\t\toutputs=gr.Textbox(label=\"Response\", lines=4),\n",
        "\t\tallow_flagging=False,\n",
        "\t)\n",
        "\tinterface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMPORTANT: You are using gradio version 4.26.0, however version 4.29.0 is available, please upgrade.\n",
            "--------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "We accept payment through various methods including credit/debit cards, PayPal, and bank transfers. Please note that we may not accept certain forms of payment due to policy restrictions."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('What are the payment options?', display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "I'm unable to provide real-time information on specific payment methods as they can vary depending on the service or platform you're using. However, I can list the most common payment methods that are widely accepted across various platforms:\n",
              "\n",
              "1. Credit/Debit Cards (Vis"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('List down the available methods of payment.', display=True)  # rephrasing same question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ho4XhfBmNUgb",
        "outputId": "080f5e8e-77c9-4440-d9e0-f2536202c302"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Our return policy allows for returns within 30 days of purchase, provided that the items are in their original condition. Please see our full return policy on our website or contact us for more information."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('May I know the return policy?', display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RLAIF: Reinforcement Learning from AI (LLM) Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate responses for the questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 1/54\n",
            "Processing row 6/54\n",
            "Processing row 11/54\n",
            "Processing row 16/54\n",
            "Processing row 21/54\n",
            "Processing row 26/54\n",
            "Processing row 31/54\n",
            "Processing row 36/54\n",
            "Processing row 41/54\n",
            "Processing row 46/54\n",
            "Processing row 51/54\n",
            "Data size: 54\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>expected_output</th>\n",
              "      <th>current_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "      <td>To track your order, please log into your acco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "      <td>I'm sorry, but I'm unable to assist with reset...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "      <td>** To return an item, you typically need to fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "      <td>The shipping time for your order depends on th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "      <td>I'm sorry, but once an order is shipped, we're...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                     expected_output  \\\n",
              "0  To track your order, please visit our website ...   \n",
              "1  No problem! To reset your password, click on t...   \n",
              "2  Sorry to hear that you need to return an item....   \n",
              "3  Our standard shipping time is 3-5 business day...   \n",
              "4  Please contact us immediately if you need to c...   \n",
              "\n",
              "                                      current_output  \n",
              "0  To track your order, please log into your acco...  \n",
              "1  I'm sorry, but I'm unable to assist with reset...  \n",
              "2  ** To return an item, you typically need to fo...  \n",
              "3  The shipping time for your order depends on th...  \n",
              "4  I'm sorry, but once an order is shipped, we're...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def already_processed(df, column_name):\n",
        "\treturn column_name in df.columns and df[column_name].notnull().all()\n",
        "\n",
        "forced_queries = True  # temp\n",
        "\n",
        "if not forced_queries and os.path.exists(all_query_responses_filepath):\n",
        "\tall_query_responses = pd.read_csv(all_query_responses_filepath)\n",
        "else:\n",
        "\t# provide expected response and current response to AI, ask to improve the response, fine-tune the model again\n",
        "\tall_query_responses = training_data.copy()\n",
        "\t# rename output to expected_output\n",
        "\tall_query_responses.rename(columns={ 'output': 'expected_output' }, inplace = True)\n",
        "\tall_query_responses['current_output'] = None\n",
        "\n",
        "\t# generate response with ask_query function\n",
        "\t# no parallel processing due to CPU heat concerns\n",
        "\tfor row_num, row in all_query_responses.iterrows():\n",
        "\t\tif row_num % 10 == 0:\n",
        "\t\t\tprint(f'Processing row {row_num+1}/{len(all_query_responses)}')\n",
        "\t\tcurrent_output = all_query_responses.at[row_num, 'current_output']\n",
        "\t\tif not current_output:\n",
        "\t\t\tresponse = ask_query(row['instruction'])\n",
        "\t\t\tall_query_responses.at[row_num, 'current_output'] = response\n",
        "\n",
        "\tall_query_responses.to_csv(all_query_responses_filepath, index=False)\n",
        "\n",
        "print('Data size:', len(all_query_responses))\n",
        "all_query_responses.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get feedback from a larger LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing rows 0 to 15 of 54 rows\n",
            "Processing rows 15 to 30 of 54 rows\n",
            "Processing rows 30 to 45 of 54 rows\n",
            "Processing rows 45 to 60 of 54 rows\n",
            "Data size: 53\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>expected_output</th>\n",
              "      <th>current_output</th>\n",
              "      <th>improved_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "      <td>To track your order, please log into your acco...</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "      <td>I'm sorry, but I'm unable to assist with reset...</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "      <td>** To return an item, you typically need to fo...</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "      <td>The shipping time for your order depends on th...</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "      <td>I'm sorry, but once an order is shipped, we're...</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                     expected_output  \\\n",
              "0  To track your order, please visit our website ...   \n",
              "1  No problem! To reset your password, click on t...   \n",
              "2  Sorry to hear that you need to return an item....   \n",
              "3  Our standard shipping time is 3-5 business day...   \n",
              "4  Please contact us immediately if you need to c...   \n",
              "\n",
              "                                      current_output  \\\n",
              "0  To track your order, please log into your acco...   \n",
              "1  I'm sorry, but I'm unable to assist with reset...   \n",
              "2  ** To return an item, you typically need to fo...   \n",
              "3  The shipping time for your order depends on th...   \n",
              "4  I'm sorry, but once an order is shipped, we're...   \n",
              "\n",
              "                                     improved_output  \n",
              "0  To track your order, please visit our website ...  \n",
              "1  No problem! To reset your password, click on t...  \n",
              "2  Sorry to hear that you need to return an item....  \n",
              "3  Our standard shipping time is 3-5 business day...  \n",
              "4  Please contact us immediately if you need to c...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forced_rlaif = False  # temp\n",
        "\n",
        "if os.path.exists(rlaif_data_filepath):\n",
        "\trlaif_data = pd.read_csv(rlaif_data_filepath)\n",
        "\tif forced_rlaif:\n",
        "\t\trlaif_data['improved_output'] = None  # set to None\n",
        "else:\n",
        "\trlaif_data = all_query_responses.copy()\n",
        "\trlaif_data['improved_output'] = None  # add column\n",
        "\n",
        "# if column is not loaded from file, or empty\n",
        "if not already_processed(rlaif_data, 'improved_output'):\n",
        "\trlaif_llm_prompt = '''\n",
        "\t\tI am fine-tuning a customer-support chatbot. \n",
        "\t\tI provided the instruction, current_output, expected_output (provided by you in the past). \n",
        "\t\tInclude csv text in the response in triple quotes ```.\n",
        "\t\treturn only these headers: instruction, improved_output. \n",
        "\t'''\n",
        "\n",
        "\t# pass 15 rows at a time to the AI to improve the response\n",
        "\tfor row_num in range(0, len(rlaif_data), 15):\n",
        "\t\tprint(f'Processing rows {row_num} to {row_num+15} of {len(rlaif_data)} rows')\n",
        "\t\tchunk = rlaif_data.iloc[row_num:row_num+15]\n",
        "\t\tcsv_text = chunk.to_csv(index=False)\n",
        "\t\tprompt = f'{rlaif_llm_prompt}\\n```{csv_text}```'\n",
        "\t\tresponse_csv = ask_larger_llm(prompt)\n",
        "\t\ttry:\n",
        "\t\t\tresponse_data = pd.read_csv(StringIO(response_csv))\n",
        "\t\texcept:\n",
        "\t\t\tprint('Failed to parse csv data from the response.')\n",
        "\t\t\tprint(response_csv)\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\t# for each row's instruction value in response_data, update the corresponding row in rlaif_improved\n",
        "\t\tfor index, row in response_data.iterrows():\n",
        "\t\t\tif 'instruction' not in row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tinstruction = row['instruction']\n",
        "\t\t\timproved_output = row['improved_output']\n",
        "\t\t\tif 'no improvement' in improved_output.lower():\n",
        "\t\t\t\timproved_output = None\n",
        "\t\t\tif improved_output is not None: # and current_output != improved_output:\n",
        "\t\t\t\tinstruction_row = rlaif_data[rlaif_data['instruction'] == instruction]\n",
        "\t\t\t\tcurrent_output = instruction_row['current_output'].values[0]\n",
        "\t\t\t\tif current_output != improved_output:\n",
        "\t\t\t\t\trlaif_data.loc[rlaif_data['instruction'] == instruction, 'improved_output'] = improved_output\n",
        "\n",
        "\trlaif_data.dropna(subset=['improved_output'], inplace=True)\n",
        "\trlaif_data.to_csv(rlaif_data_filepath, index=False)\n",
        "\n",
        "print('Data size:', len(rlaif_data))\n",
        "rlaif_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fine-tuning using the RLAIF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "rlaif_prompt = '''You are a customer support chatbot.\n",
        "I listed improvements from human feedback.\n",
        "Learn from the sample instruction, current response, and improved response provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Current Response:\n",
        "{}\n",
        "\n",
        "### Improved response:\n",
        "{}'''\n",
        "\n",
        "def create_rlaif_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\tcurrent_outputs = training_data['current_output']\n",
        "\timproved_outputs = training_data['improved_output']\n",
        "\ttexts = []\n",
        "\tfor instruction, current_output, improved_output in zip(instructions, current_outputs, improved_outputs):\n",
        "\t\ttext = rlaif_prompt.format(instruction, current_output, improved_output) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset\n",
        "\n",
        "train_model(create_rlaif_dataset(rlaif_data), force_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RLHF: Reinforcement Learning from Human Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Emulating human feedback with a larger LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "      <th>like_dislike_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>You can track your order by logging into your ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>To return an item, please visit our website an...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Yes, you can cancel your order within 24 hours...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want to change my shipping address. Can you ...</td>\n",
              "      <td>I'd be happy to help you update your shipping ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I want to know more about your products.</td>\n",
              "      <td>We offer a wide range of products in various c...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         instruction  \\\n",
              "0                      Hi, I want to track my order.   \n",
              "1      I want to return an item. What's the process?   \n",
              "2                             Can I cancel my order?   \n",
              "3  I want to change my shipping address. Can you ...   \n",
              "4           I want to know more about your products.   \n",
              "\n",
              "                                              output  like_dislike_status  \n",
              "0  You can track your order by logging into your ...                 True  \n",
              "1  To return an item, please visit our website an...                False  \n",
              "2  Yes, you can cancel your order within 24 hours...                 True  \n",
              "3  I'd be happy to help you update your shipping ...                 True  \n",
              "4  We offer a wide range of products in various c...                False  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forced_rlhf = True  # temp\n",
        "\n",
        "if os.path.exists(rlhf_data_filepath):\n",
        "\trlhf_data = pd.read_csv(rlhf_data_filepath)\n",
        "\tif forced_rlhf:\n",
        "\t\trlhf_data['like_dislike_status'] = None  # set to None\n",
        "else:\n",
        "\trlhf_data = all_query_responses.copy()\n",
        "\trlhf_data['like_dislike_status'] = None  # add column\n",
        "\n",
        "if not already_processed(rlhf_data, 'like_dislike_status'):\n",
        "\trlhf_llm_prompt = '''\n",
        "\t\tI am emulating RLHF (human feedback) for a customer-support chatbot.\n",
        "\t\tI provided the \"instruction\" column.\n",
        "\t\tSelect random instructions and provide a \"like_dislike_status\" value (True or False).\n",
        "\t\tSame instruction can be repeated with different output and like_dislike_status values. Some instructions can be skipped.\n",
        "\t\treturn only these headers: instruction, output, like_dislike_status.\n",
        "\t\tInclude csv text in the response in triple quotes ```.\n",
        "\t'''\n",
        "\tcsv_text = rlhf_data[['instruction']].to_csv(index=False)\n",
        "\tprompt = f'{rlhf_llm_prompt}\\n```{csv_text}```'\n",
        "\tresponse_csv = ask_larger_llm(prompt)\n",
        "\ttry:\n",
        "\t\trlhf_data = pd.read_csv(StringIO(response_csv))\n",
        "\texcept:\n",
        "\t\tprint('Failed to parse csv data from the response.')\n",
        "\t\tprint(response_csv)\n",
        "\trlhf_data.to_csv(rlhf_data_filepath, index=False)\n",
        "\n",
        "rlhf_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fine-tuning using the RLHF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "rlhf_prompt = '''You are a customer support chatbot.\n",
        "I listed improvements from human feedback.\n",
        "Learn from the sample instruction, current response, and Like/Dislike status provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Current Response:\n",
        "{}\n",
        "\n",
        "### User Like/Dislike Status:\n",
        "{}'''\n",
        "\n",
        "def create_rlhf_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\toutputs = training_data['output']\n",
        "\tlike_dislike_statuses = training_data['like_dislike_status']\n",
        "\ttexts = []\n",
        "\tfor instruction, output, like_dislike_status in zip(instructions, outputs, like_dislike_statuses):\n",
        "\t\ttext = rlhf_prompt.format(instruction, output, like_dislike_status) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset\n",
        "\n",
        "train_model(create_rlhf_dataset(rlhf_data), force_train=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
