{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href='https://colab.research.google.com/github/prane-eth/AI_projects/blob/main/projects/LLM_fine-tuning.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUnsdLr1Dn-"
      },
      "source": [
        "### Project: Fine-tuning a language model\n",
        "\n",
        "Demo:\n",
        "![LLMs - Finetuning, RLAIF, and RLHF](../Demo/LLM_Fine-tuning.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aGqbJDNf1DoA"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    __import__('unsloth')\n",
        "except ImportError:\n",
        "\t# %%capture\n",
        "\t%pip install pandas groq python-dotenv datasets\n",
        "\t%pip install 'unsloth @ git+https://github.com/unslothai/unsloth.git'\n",
        "\t%pip install --no-deps 'xformers<0.0.26' trl tyro peft accelerate bitsandbytes\n",
        "\t%pip install torch==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "from datasets import Dataset\n",
        "from groq import Groq\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import TrainingArguments, set_seed\n",
        "from trl import SFTTrainer\n",
        "from unsloth import FastLanguageModel\n",
        "from common_functions import display_md\n",
        "\n",
        "HOSTING_ENABLED = True\n",
        "\n",
        "random_state = 42\n",
        "set_seed(random_state)\n",
        "\n",
        "datasets_folder = 'datasets'\n",
        "if not os.path.exists(datasets_folder):\n",
        "\tos.makedirs(datasets_folder)\n",
        "\n",
        "topic = 'customer_support'\n",
        "datasets_folder = os.path.join(datasets_folder, topic + '_bot')  # create sub-folder for the topic\n",
        "if not os.path.exists(datasets_folder):\n",
        "\tos.makedirs(datasets_folder)\n",
        "\n",
        "finetune_data_filepath = os.path.join(datasets_folder, f'finetune_data.csv')\n",
        "model_checkpoint_path = os.path.join(datasets_folder, f'saved_model')\n",
        "all_query_responses_filepath = os.path.join(datasets_folder, f'all_query_responses.csv')\n",
        "rlaif_data_filepath = os.path.join(datasets_folder, f'rlaif_data.csv')\n",
        "rlhf_data_filepath = os.path.join(datasets_folder, f'rlhf_data.csv')\n",
        "chat_history_filepath = os.path.join(datasets_folder, f'chat_history.csv')\n",
        "\n",
        "groq_api_key = os.getenv('GROQ_API_KEY')\n",
        "\n",
        "if not groq_api_key and 'google.colab' in sys.modules:\n",
        "\tfrom google.colab import userdata\n",
        "\tgroq_api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "if not groq_api_key:\n",
        "\traise ValueError('GROQ_API_KEY is not set in the environment variables')\n",
        "\n",
        "if os.path.exists(chat_history_filepath):\n",
        "\tchat_history = pd.read_csv(chat_history_filepath)\n",
        "else:\n",
        "\tchat_history = pd.DataFrame(columns=['query', 'response', 'timestamp'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F06mXO-e1DoB"
      },
      "source": [
        "### Generate synthetic data for fine-tuning\n",
        "**Data generation using an LLM**: Uses a Large model like Llama-3 (70B) to generate data to use for fine-tuning a small model like Phi 3 (3.8B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data size: 54\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                              output  \n",
              "0  To track your order, please visit our website ...  \n",
              "1  No problem! To reset your password, click on t...  \n",
              "2  Sorry to hear that you need to return an item....  \n",
              "3  Our standard shipping time is 3-5 business day...  \n",
              "4  Please contact us immediately if you need to c...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "def ask_larger_llm(prompt, model='llama3-70b-8192', return_quoted=True):\n",
        "\tchat_completion = client.chat.completions.create(\n",
        "\t\tmessages=[{ 'role': 'user', 'content': prompt }],\n",
        "\t\tmodel=model,\n",
        "\t)\n",
        "\tresponse = chat_completion.choices[0].message.content\n",
        "\tif not response:\n",
        "\t\traise SystemExit('No response from the API.')\n",
        "\n",
        "\tif not return_quoted:\n",
        "\t\treturn response\n",
        "\n",
        "\t# if response doesnt end with ``` then add it\n",
        "\tif not response.endswith('```'):\n",
        "\t\tresponse += '```'\n",
        "\n",
        "\t# get the data from the response - csv text between triple quotes ``` ```\n",
        "\tmatch = re.search(r'```(.*?)```', response, re.DOTALL)\n",
        "\tif match:\n",
        "\t\tquoted_text = match.group(1)\n",
        "\t\tquoted_text = quoted_text.strip()\n",
        "\n",
        "\t\t# sometimes, quotes or special characters are used to start and end the text. remove them\n",
        "\t\t# if quoted_text[0] == quoted_text[-1]:\n",
        "\t\t# \tquoted_text = quoted_text[1:-1]\n",
        "\t\t# remove only if first line doesnt end with same character\n",
        "\t\tfirst_line_end_character = quoted_text.split('\\n')[0][-1] if '\\n' in quoted_text else None\n",
        "\t\tif quoted_text[0] == quoted_text[-1] and quoted_text[0] != first_line_end_character:\n",
        "\t\t\tquoted_text = quoted_text[1:-1]\n",
        "\n",
        "\t\treturn quoted_text\n",
        "\telse:\n",
        "\t\tprint(response)\n",
        "\t\traise SystemExit('No data found in the response.')\n",
        "\n",
        "\n",
        "# if file exists, read it\n",
        "if os.path.exists(finetune_data_filepath):\n",
        "\twith open(finetune_data_filepath, 'r') as file:\n",
        "\t\tcsv_text = file.read()\n",
        "else:\n",
        "\tnum_lines = 100\n",
        "\tllm_training_data_prompt = f'Generate high-quality data for fine-tuning in csv for {topic} chatbot' \\\n",
        "\t\t\tf' for an ecommerce platform in at least {num_lines} lines of data. ' \\\n",
        "\t\t\t'Include the csv file text in triple quotes ```. ' \\\n",
        "\t\t\t'response should include no other text. fields: instruction, output.'\n",
        "\tcsv_text = ask_larger_llm(llm_training_data_prompt)\n",
        "\twith open(finetune_data_filepath, 'w') as file:\n",
        "\t\tfile.write(csv_text)\n",
        "\n",
        "\n",
        "training_data = pd.read_csv(finetune_data_filepath)\n",
        "print(f'Data size: {len(training_data)}')\n",
        "\n",
        "training_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmqi8x9d1DoC"
      },
      "source": [
        "### Prepare the model for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "YEpYrg7f1DoC",
        "outputId": "1a999437-b74e-4e92-fe23-37aa33ac3e0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
            "   \\\\   /|    GPU: NVIDIA GeForce RTX 3050 Laptop GPU. Max memory: 3.804 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: datasets/customer_support_bot/saved_model has no tokenizer.model file.\n",
            "Just informing you about this - this is not a critical error.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = 2048\n",
        "model = None\n",
        "tokenizer = None\n",
        "restored_finetuned_model = False\n",
        "device = 'cuda'  # 'cuda' or 'cpu'\n",
        "\n",
        "if os.path.exists(model_checkpoint_path):\n",
        "    try:\n",
        "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_checkpoint_path, trust_remote_code=True,\n",
        "            dtype=None, load_in_4bit = True, device_map=device,\n",
        "        )\n",
        "        restored_finetuned_model = True\n",
        "        print('Model loaded successfully.')\n",
        "    except Exception as e:\n",
        "        print('Error loading the model. Will train a new model.')\n",
        "        print(e)\n",
        "\n",
        "else:  # if not restored_finetuned_model:\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "\t\tmodel_name = 'unsloth/Phi-3-mini-4k-instruct',\n",
        "\t\tmax_seq_length = max_seq_length,\n",
        "\t\tdtype = None,  # None for auto-detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "\t\tload_in_4bit = True,  # 4-bit quantization to reduce memory usage\n",
        "\t)\n",
        "\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "\t\tmodel,\n",
        "\t\tr = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "\t\ttarget_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj',\n",
        "\t\t\t\t\t\t'gate_proj', 'up_proj', 'down_proj',],\n",
        "\t\tlora_alpha = 16,\n",
        "\t\tlora_dropout = 0,  # Supports any, but = 0 is optimized\n",
        "\t\tbias = 'none',  # Supports any, but = 'none' is optimized\n",
        "\t\t# 'unsloth' uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "\t\tuse_gradient_checkpointing = 'unsloth', # True or 'unsloth' for very long context\n",
        "\t\trandom_state = random_state,\n",
        "\t\tuse_rslora = False,\n",
        "\t\tloftq_config = None,\n",
        "\t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR_MEXIHGV6d"
      },
      "source": [
        "### Prepare the dataset for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3dSoURKgGgnN"
      },
      "outputs": [],
      "source": [
        "finetune_prompt = '''You are a customer support chatbot.\n",
        "Below is an instruction that describes a task that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Learn from the sample instruction and sample response provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}'''\n",
        "\n",
        "def create_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\toutputs = training_data['output']\n",
        "\ttexts = []\n",
        "\tfor instruction, output in zip(instructions, outputs):\n",
        "\t\t# without EOS_TOKEN, generation will go on forever\n",
        "\t\ttext = finetune_prompt.format(instruction, output) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT8lV4-IGSOT"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "-gCr-uZL1DoC",
        "outputId": "3335525d-afca-436b-98bf-d3e6124f3eb7"
      },
      "outputs": [],
      "source": [
        "trainer = None\n",
        "\n",
        "def train_model(train_dataset, force_train=False):\n",
        "\tglobal trainer, model, tokenizer, restored_finetuned_model\n",
        "\n",
        "\tif not force_train and not restored_finetuned_model:  # if restoration failed\n",
        "\t\tprint('Model restoration failed. Training a new model.')\n",
        "\t\tforce_train = True\n",
        "\n",
        "\tif force_train:\n",
        "\t\ttrainer = SFTTrainer(\n",
        "\t\t\tmodel = model,\n",
        "\t\t\ttokenizer = tokenizer,\n",
        "\t\t\ttrain_dataset = train_dataset,\n",
        "\t\t\tdataset_text_field = 'text',\n",
        "\t\t\tmax_seq_length = max_seq_length,\n",
        "\t\t\tdataset_num_proc = 2,\n",
        "\t\t\tpacking = False, # Can make training 5x faster for short sequences.\n",
        "\t\t\targs = TrainingArguments(\n",
        "\t\t\t\tper_device_train_batch_size = 2,\n",
        "\t\t\t\tgradient_accumulation_steps = 4,\n",
        "\t\t\t\twarmup_steps = 5,\n",
        "\t\t\t\tmax_steps = 60,\n",
        "\t\t\t\tlearning_rate = 2e-4,\n",
        "\t\t\t\tfp16 = not torch.cuda.is_bf16_supported(),\n",
        "\t\t\t\tbf16 = torch.cuda.is_bf16_supported(),\n",
        "\t\t\t\tlogging_steps = 1,\n",
        "\t\t\t\toptim = 'adamw_8bit',\n",
        "\t\t\t\tweight_decay = 0.01,\n",
        "\t\t\t\tlr_scheduler_type = 'linear',\n",
        "\t\t\t\tseed = random_state,\n",
        "\t\t\t\toutput_dir = model_checkpoint_path,\n",
        "\t\t\t),\n",
        "\t\t)\n",
        "\n",
        "\t\ttrainer.train()\n",
        "\t\tmodel.save_pretrained(model_checkpoint_path)\n",
        "\t\ttokenizer.save_pretrained(model_checkpoint_path)\n",
        "\t\t# trainer.save_model(model_checkpoint_path)\n",
        "\t\t# model.save_pretrained_merged(model_checkpoint_path + '-merged', tokenizer, save_method='merged_16bit')\n",
        "\n",
        "train_model(create_dataset(training_data), force_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcMm5av_1DoC"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W-5u1umL1DoC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/praneeth/Desktop/AI_projects/.venv/lib/python3.10/site-packages/gradio/interface.py:374: UserWarning: The `allow_flagging` parameter in `Interface` nowtakes a string value ('auto', 'manual', or 'never'), not a boolean. Setting parameter to: 'never'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "query_prompt = '''You are a customer support chatbot. Respond to this query.\n",
        "\n",
        "### Query:\n",
        "{}\n",
        "\n",
        "### Response:'''  # leave this blank for generation!\n",
        "\n",
        "\n",
        "def ask_query(query, display=False):\n",
        "\tinputs = tokenizer([\n",
        "\t\t# query\n",
        "\t\tquery_prompt.format(query)\n",
        "\t], return_tensors = 'pt').to(device)\n",
        "\n",
        "\t# # Streaming outputs\n",
        "\t# text_streamer = TextStreamer(tokenizer)\n",
        "\t# _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n",
        "\n",
        "\toutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "\toutput = ''.join(tokenizer.batch_decode(outputs))\n",
        "\n",
        "\t# find 'Response: ' and get text after that\n",
        "\tif 'Response:' in output:\n",
        "\t\toutput = output[output.find('Response:') + len('Response:'):]\n",
        "\tif '<|assistant|>' in output:\n",
        "\t\toutput = output[output.find('<|assistant|>') + len('<|assistant|>'):]\n",
        "\tif '[Response]:' in output:\n",
        "\t\toutput = output[output.find('[Response]:') + len('[Response]:'):]\n",
        "\n",
        "\t# remove '<|endoftext|>' from end\n",
        "\tif output.endswith('<|endoftext|>'):\n",
        "\t\toutput = output[:-len('<|endoftext|>')]\n",
        "\n",
        "\toutput = output.strip()\n",
        "\n",
        "\tchat_history.loc[len(chat_history)] = [query, output, pd.Timestamp.now()]\n",
        "\tchat_history.to_csv(chat_history_filepath, index=False)\n",
        "\n",
        "\tif display:\n",
        "\t\tdisplay_md(output)\n",
        "\telse:\n",
        "\t\treturn output\n",
        "\n",
        "if HOSTING_ENABLED:\n",
        "\timport gradio as gr\n",
        "\tdef get_bot_response(query):\n",
        "\t\treturn ask_query(query)\n",
        "\tinterface=gr.Interface(\n",
        "\t\tfn=get_bot_response,\n",
        "\t\tinputs=gr.Textbox(\n",
        "\t\t\tlines=2, placeholder=\"Enter query here\",\n",
        "\t\t\tlabel=\"Query\"\n",
        "\t\t),\n",
        "\t\toutputs=gr.Textbox(label=\"Response\", lines=4),\n",
        "\t\tallow_flagging=False,\n",
        "\t)\n",
        "\tinterface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMPORTANT: You are using gradio version 4.26.0, however version 4.29.0 is available, please upgrade.\n",
            "--------\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "We accept payments via credit/debit cards, PayPal, and bank transfers. Please contact us if you have any questions about payment options."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('What are the payment options?', display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "We accept the following methods of payment:\n",
              "- Credit/Debit Cards\n",
              "- PayPal\n",
              "- Bank Transfer\n",
              "- Apple Pay\n",
              "- Google Pay\n",
              "\n",
              "Please note that we may not accept certain payment methods in the future."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('List down the available methods of payment.', display=True)  # rephrasing same question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ho4XhfBmNUgb",
        "outputId": "080f5e8e-77c9-4440-d9e0-f2536202c302"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Our return policy allows for returns within [time frame]. Please see our full return policy for details."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('May I know the return policy?', display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RLAIF: Reinforcement Learning from AI (LLM) Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate responses for the questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data size: 54\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>expected_output</th>\n",
              "      <th>current_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "      <td>To track your order, please log into your acco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "      <td>I'm sorry, but I'm unable to assist with reset...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "      <td>** To return an item, you typically need to fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "      <td>The shipping time for your order depends on th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "      <td>I'm sorry, but once an order is shipped, we're...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                     expected_output  \\\n",
              "0  To track your order, please visit our website ...   \n",
              "1  No problem! To reset your password, click on t...   \n",
              "2  Sorry to hear that you need to return an item....   \n",
              "3  Our standard shipping time is 3-5 business day...   \n",
              "4  Please contact us immediately if you need to c...   \n",
              "\n",
              "                                      current_output  \n",
              "0  To track your order, please log into your acco...  \n",
              "1  I'm sorry, but I'm unable to assist with reset...  \n",
              "2  ** To return an item, you typically need to fo...  \n",
              "3  The shipping time for your order depends on th...  \n",
              "4  I'm sorry, but once an order is shipped, we're...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def already_processed(df, column_name):\n",
        "\treturn column_name in df.columns and df[column_name].notnull().all()\n",
        "\n",
        "forced_queries = False  # temp\n",
        "\n",
        "if not forced_queries and os.path.exists(all_query_responses_filepath):\n",
        "\tall_query_responses = pd.read_csv(all_query_responses_filepath)\n",
        "else:\n",
        "\t# provide expected response and current response to AI, ask to improve the response, fine-tune the model again\n",
        "\tall_query_responses = training_data.copy()\n",
        "\t# rename output to expected_output\n",
        "\tall_query_responses.rename(columns={ 'output': 'expected_output' }, inplace = True)\n",
        "\tall_query_responses['current_output'] = None\n",
        "\n",
        "\t# generate response with ask_query function\n",
        "\t# no parallel processing due to CPU heat concerns\n",
        "\tfor row_num, row in all_query_responses.iterrows():\n",
        "\t\tif row_num % 10 == 0:\n",
        "\t\t\tprint(f'Processing row {row_num+1}/{len(all_query_responses)}')\n",
        "\t\tcurrent_output = all_query_responses.at[row_num, 'current_output']\n",
        "\t\tif not current_output:\n",
        "\t\t\tresponse = ask_query(row['instruction'])\n",
        "\t\t\tall_query_responses.at[row_num, 'current_output'] = response\n",
        "\n",
        "\tall_query_responses.to_csv(all_query_responses_filepath, index=False)\n",
        "\n",
        "print('Data size:', len(all_query_responses))\n",
        "all_query_responses.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get feedback from a larger LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data size: 53\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>expected_output</th>\n",
              "      <th>current_output</th>\n",
              "      <th>improved_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "      <td>To track your order, please log into your acco...</td>\n",
              "      <td>To track your order, please visit our website ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I forgot my password. Can you help me?</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "      <td>I'm sorry, but I'm unable to assist with reset...</td>\n",
              "      <td>No problem! To reset your password, click on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "      <td>** To return an item, you typically need to fo...</td>\n",
              "      <td>Sorry to hear that you need to return an item....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the shipping time for my order?</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "      <td>The shipping time for your order depends on th...</td>\n",
              "      <td>Our standard shipping time is 3-5 business day...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "      <td>I'm sorry, but once an order is shipped, we're...</td>\n",
              "      <td>Please contact us immediately if you need to c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     instruction  \\\n",
              "0                  Hi, I want to track my order.   \n",
              "1         I forgot my password. Can you help me?   \n",
              "2  I want to return an item. What's the process?   \n",
              "3        What is the shipping time for my order?   \n",
              "4                         Can I cancel my order?   \n",
              "\n",
              "                                     expected_output  \\\n",
              "0  To track your order, please visit our website ...   \n",
              "1  No problem! To reset your password, click on t...   \n",
              "2  Sorry to hear that you need to return an item....   \n",
              "3  Our standard shipping time is 3-5 business day...   \n",
              "4  Please contact us immediately if you need to c...   \n",
              "\n",
              "                                      current_output  \\\n",
              "0  To track your order, please log into your acco...   \n",
              "1  I'm sorry, but I'm unable to assist with reset...   \n",
              "2  ** To return an item, you typically need to fo...   \n",
              "3  The shipping time for your order depends on th...   \n",
              "4  I'm sorry, but once an order is shipped, we're...   \n",
              "\n",
              "                                     improved_output  \n",
              "0  To track your order, please visit our website ...  \n",
              "1  No problem! To reset your password, click on t...  \n",
              "2  Sorry to hear that you need to return an item....  \n",
              "3  Our standard shipping time is 3-5 business day...  \n",
              "4  Please contact us immediately if you need to c...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forced_rlaif = False  # temp\n",
        "\n",
        "if os.path.exists(rlaif_data_filepath):\n",
        "\trlaif_data = pd.read_csv(rlaif_data_filepath)\n",
        "\tif forced_rlaif:\n",
        "\t\trlaif_data['improved_output'] = None  # set to None\n",
        "else:\n",
        "\trlaif_data = all_query_responses.copy()\n",
        "\trlaif_data['improved_output'] = None  # add column\n",
        "\n",
        "# if column is not loaded from file, or empty\n",
        "if not already_processed(rlaif_data, 'improved_output'):\n",
        "\trlaif_llm_prompt = '''\n",
        "\t\tI am fine-tuning a customer-support chatbot. \n",
        "\t\tI provided the instruction, current_output, expected_output (provided by you in the past). \n",
        "\t\tInclude csv text in the response in triple quotes ```.\n",
        "\t\treturn only these headers: instruction, improved_output. \n",
        "\t'''\n",
        "\n",
        "\t# pass 15 rows at a time to the AI to improve the response\n",
        "\tfor row_num in range(0, len(rlaif_data), 15):\n",
        "\t\tprint(f'Processing rows {row_num} to {row_num+15} of {len(rlaif_data)} rows')\n",
        "\t\tchunk = rlaif_data.iloc[row_num:row_num+15]\n",
        "\t\tcsv_text = chunk.to_csv(index=False)\n",
        "\t\tresponse_csv = ask_larger_llm(f'{rlaif_llm_prompt}\\n```{csv_text}```')\n",
        "\t\ttry:\n",
        "\t\t\tresponse_data = pd.read_csv(StringIO(response_csv))\n",
        "\t\texcept:\n",
        "\t\t\tprint('Failed to parse csv data from the response.')\n",
        "\t\t\tprint(response_csv)\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\t# for each row's instruction value in response_data, update the corresponding row in rlaif_improved\n",
        "\t\tfor index, row in response_data.iterrows():\n",
        "\t\t\tif 'instruction' not in row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tinstruction = row['instruction']\n",
        "\t\t\timproved_output = row['improved_output']\n",
        "\t\t\tif 'no improvement' in improved_output.lower():\n",
        "\t\t\t\timproved_output = None\n",
        "\t\t\tif improved_output is not None: # and current_output != improved_output:\n",
        "\t\t\t\tinstruction_row = rlaif_data[rlaif_data['instruction'] == instruction]\n",
        "\t\t\t\tcurrent_output = instruction_row['current_output'].values[0]\n",
        "\t\t\t\tif current_output != improved_output:\n",
        "\t\t\t\t\trlaif_data.loc[rlaif_data['instruction'] == instruction, 'improved_output'] = improved_output\n",
        "\n",
        "\trlaif_data.dropna(subset=['improved_output'], inplace=True)\n",
        "\trlaif_data.to_csv(rlaif_data_filepath, index=False)\n",
        "\n",
        "print('Data size:', len(rlaif_data))\n",
        "rlaif_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fine-tuning using the RLAIF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "rlaif_prompt = '''You are a customer support chatbot.\n",
        "I listed improvements from human feedback.\n",
        "Learn from the sample instruction, current response, and improved response provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Current Response:\n",
        "{}\n",
        "\n",
        "### Improved response:\n",
        "{}'''\n",
        "\n",
        "def create_rlaif_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\tcurrent_outputs = training_data['current_output']\n",
        "\timproved_outputs = training_data['improved_output']\n",
        "\ttexts = []\n",
        "\tfor instruction, current_output, improved_output in zip(instructions, current_outputs, improved_outputs):\n",
        "\t\ttext = rlaif_prompt.format(instruction, current_output, improved_output) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset\n",
        "\n",
        "train_model(create_rlaif_dataset(rlaif_data), force_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RLHF: Reinforcement Learning from Human Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Emulating human feedback with a larger LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "      <th>like_dislike_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, I want to track my order.</td>\n",
              "      <td>You can track your order by logging into your ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I want to return an item. What's the process?</td>\n",
              "      <td>To return an item, please visit our website an...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Can I cancel my order?</td>\n",
              "      <td>Yes, you can cancel your order within 24 hours...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want to change my shipping address. Can you ...</td>\n",
              "      <td>I'd be happy to help you update your shipping ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I want to know more about your products.</td>\n",
              "      <td>We offer a wide range of products in various c...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         instruction  \\\n",
              "0                      Hi, I want to track my order.   \n",
              "1      I want to return an item. What's the process?   \n",
              "2                             Can I cancel my order?   \n",
              "3  I want to change my shipping address. Can you ...   \n",
              "4           I want to know more about your products.   \n",
              "\n",
              "                                              output  like_dislike_status  \n",
              "0  You can track your order by logging into your ...                 True  \n",
              "1  To return an item, please visit our website an...                False  \n",
              "2  Yes, you can cancel your order within 24 hours...                 True  \n",
              "3  I'd be happy to help you update your shipping ...                 True  \n",
              "4  We offer a wide range of products in various c...                False  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forced_rlhf = False\n",
        "\n",
        "if os.path.exists(rlhf_data_filepath):\n",
        "\trlhf_data = pd.read_csv(rlhf_data_filepath)\n",
        "\tif forced_rlhf:\n",
        "\t\trlhf_data['like_dislike_status'] = None  # set to None\n",
        "else:\n",
        "\trlhf_data = all_query_responses.copy()\n",
        "\trlhf_data['like_dislike_status'] = None  # add column\n",
        "\n",
        "if not already_processed(rlhf_data, 'like_dislike_status'):\n",
        "\trlhf_llm_prompt = '''\n",
        "\t\tI am emulating RLHF (human feedback) for a customer-support chatbot.\n",
        "\t\tI provided the \"instruction\" column.\n",
        "\t\tSelect random instructions and provide a \"like_dislike_status\" value (True or False).\n",
        "\t\tSame instruction can be repeated with different output and like_dislike_status values. Some instructions can be skipped.\n",
        "\t\treturn only these headers: instruction, output, like_dislike_status.\n",
        "\t\tInclude csv text in the response in triple quotes ```.\n",
        "\t'''\n",
        "\tcsv_text = rlhf_data[['instruction']].to_csv(index=False)\n",
        "\tresponse_csv = ask_larger_llm(f'{rlhf_llm_prompt}\\n```{csv_text}```')\n",
        "\ttry:\n",
        "\t\trlhf_data = pd.read_csv(StringIO(response_csv))\n",
        "\texcept:\n",
        "\t\tprint('Failed to parse csv data from the response.')\n",
        "\t\tprint(response_csv)\n",
        "\trlhf_data.to_csv(rlhf_data_filepath, index=False)\n",
        "\n",
        "rlhf_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fine-tuning using the RLHF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "rlhf_prompt = '''You are a customer support chatbot.\n",
        "I listed improvements from human feedback.\n",
        "Learn from the sample instruction, current response, and Like/Dislike status provided.\n",
        "\n",
        "### Sample Instruction:\n",
        "{}\n",
        "\n",
        "### Current Response:\n",
        "{}\n",
        "\n",
        "### User Like/Dislike Status:\n",
        "{}'''\n",
        "\n",
        "def create_rlhf_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\toutputs = training_data['output']\n",
        "\tlike_dislike_statuses = training_data['like_dislike_status']\n",
        "\ttexts = []\n",
        "\tfor instruction, output, like_dislike_status in zip(instructions, outputs, like_dislike_statuses):\n",
        "\t\ttext = rlhf_prompt.format(instruction, output, like_dislike_status) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset\n",
        "\n",
        "train_model(create_rlhf_dataset(rlhf_data), force_train=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
