{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents in LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain.utilities import PythonREPL\n",
    "from common_functions import get_ollama\n",
    "\n",
    "llm = get_ollama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praneeth/Desktop/AI_projects/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "tools = load_tools([\n",
    "    'requests_all', 'llm-math', 'openweathermap-api',\n",
    "    'google-serper', 'ddg-search'  # DuckDuckGo search tool\n",
    "], llm=llm)  # 'wikipedia', 'google-search'\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "class ArgsSchema(BaseModel):\n",
    "    command: str\n",
    "\n",
    "tools.append(StructuredTool(\n",
    "\tname='Python repl',\n",
    "\tfunc=python_repl.run,\n",
    "\tdescription='useful when you need to run python code. ',\n",
    "\targs_schema=ArgsSchema,\n",
    "))\n",
    "\n",
    "agent = initialize_agent(\n",
    "\ttools,\n",
    "\tllm,\n",
    "\tagent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,  # uses Chain-of-Thought\n",
    "\tverbose=True,\n",
    "\thandle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "def ask_query(query):\n",
    "\tresponse = agent.invoke({'input': query})\n",
    "\tif isinstance(response, dict):\n",
    "\t\tresponse = response.get('output')\n",
    "\tresponse = response.strip()\n",
    "\n",
    "\tif '{' in response:\n",
    "\t\t# get text from first { to last }\n",
    "\t\tresponse = response[response.index('{'):response.rindex('}')+1]\n",
    "\tif response[0] == '{':\n",
    "\t\tresponse_json = json.loads(response)\n",
    "\t\tanswer = response_json.get('action_input')\n",
    "\t\treturn answer\n",
    "\n",
    "\tif '<|eot_id|>' in response:  # get part before that\n",
    "\t\tresponse = response[:response.index('<|eot_id|>')]\n",
    "\treturn response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought:\n",
      "Action:\n",
      "```\n",
      "{\n",
      "   \"action\": \"Python repl\",\n",
      "   \"action_input\": \"print('hello world')\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mhello world\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI'm glad to continue!\n",
      "\n",
      "Thought:\n",
      "The human wants me to write and execute python code to print \"hello world\". We've already done that, and it worked perfectly!\n",
      "Action:\n",
      "```{\n",
      "   \"action\": \"Final Answer\", \n",
      "   \"action_input\": \"No further action required. The task is complete.\"\n",
      "}```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No further action required. The task is complete.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_query('Write and execute python code to print hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought:\n",
      "The human is asking about the current President of France.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "   \"action\": \"Final Answer\",\n",
      "   \"action_input\": \"Emmanuel Macron\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Emmanuel Macron'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_query('Who is the current President of France in May 2024?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought:\n",
      "Action:\n",
      "```\n",
      "{\n",
      "   \"action\": \"open_weather_map\",\n",
      "   \"action_input\": \"Paris,FR\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn Paris,FR, the current weather is as follows:\n",
      "Detailed status: clear sky\n",
      "Wind speed: 3.09 m/s, direction: 50°\n",
      "Humidity: 77%\n",
      "Temperature: \n",
      "  - Current: 16.78°C\n",
      "  - High: 19.03°C\n",
      "  - Low: 15.0°C\n",
      "  - Feels like: 16.52°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 0%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought:\n",
      "Action: \n",
      "```{\n",
      "    \"action\": \"Final Answer\", \n",
      "    \"action_input\": \"The current weather in Paris, FR is clear sky with a temperature of 16.78°C.\"\n",
      "}```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather in Paris, FR is clear sky with a temperature of 16.78°C.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_query('What is weather of the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I know that George Washington is one of the most well-known American founding fathers.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"February 22, 1732\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'February 22, 1732'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_query('On which date was George Washington born?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For more projects, open [README.md](/README.md)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused code\n",
    "\n",
    "# from langchain import hub# print('Pulling prompt...', end=' ', flush=True)\n",
    "# prompt = hub.pull('hwchase17/structured-chat-agent')\n",
    "# print('done')\n",
    "# agent = create_structured_chat_agent(tools, llm, prompt=prompt)\n",
    "# agent_executor = AgentExecutor(\n",
    "#     agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    "# )\n",
    "\n",
    "\n",
    "# Memorizer tool\n",
    "# from langchain.tools import BaseTool, tool, Tool\n",
    "# memory_filepath = os.path.join(datasets_dir, 'memory.txt')\n",
    "\n",
    "# @tool\n",
    "# def get_memory() -> list[str]:\n",
    "# \t'Reads entire memory from file. Use this when user asks to remember the things' \\\n",
    "# \t\t'Inputs: None. Outputs: List of strings'\n",
    "# \tif not os.path.exists(memory_filepath):\n",
    "# \t\treturn None\n",
    "# \twith open(memory_filepath) as f:\n",
    "# \t\tmemory = f.readlines()\n",
    "# \treturn [line.strip() for line in memory]\n",
    "\n",
    "# @tool\n",
    "# def set_memory(memory: list[str]):\n",
    "# \t'Rewrites entire memory to file. Use this when user asks to remember the things' \\\n",
    "# \t\t'Inputs: List of strings. Outputs: None'\n",
    "# \twith open(memory_filepath, 'w') as f:\n",
    "# \t\tf.writelines(memory)\n",
    "# \tprint('set_memory: rewrote', len(memory), 'lines')\n",
    "\n",
    "# tools = [set_memory, get_memory] + tools\n",
    "\n",
    "# ask_query('Remember I have put my keys on the table')\n",
    "# ask_query('Where are my keys?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
