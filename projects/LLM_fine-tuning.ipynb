{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href='https://colab.research.google.com/github/prane-eth/AI_projects/blob/main/projects/LLM_fine-tuning.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUnsdLr1Dn-"
      },
      "source": [
        "### Project: Fine-tuning a language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aGqbJDNf1DoA"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    __import__('unsloth')\n",
        "except ImportError:\n",
        "\t# %%capture\n",
        "\t%pip install pandas groq python-dotenv datasets\n",
        "\t%pip install 'unsloth @ git+https://github.com/unslothai/unsloth.git'\n",
        "\t%pip install --no-deps 'xformers<0.0.26' trl tyro peft accelerate bitsandbytes\n",
        "\t%pip install torch==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "from datasets import Dataset\n",
        "from groq import Groq\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import TrainingArguments, set_seed\n",
        "from trl import SFTTrainer\n",
        "from unsloth import FastLanguageModel\n",
        "from common_functions import display_md\n",
        "\n",
        "random_state = 42\n",
        "set_seed(random_state)\n",
        "\n",
        "datasets_folder = 'datasets'\n",
        "if not os.path.exists(datasets_folder):\n",
        "\tos.makedirs(datasets_folder)\n",
        "\n",
        "topic = 'customer_support'\n",
        "data_filename = os.path.join(datasets_folder, f'{topic}_bot_finetune_data.csv')\n",
        "model_checkpoint_path = os.path.join(datasets_folder, f'{topic}_saved_model')\n",
        "rlaif_data_filepath = os.path.join(datasets_folder, f'{topic}_bot_rlaif_data.csv')\n",
        "\n",
        "groq_api_key = os.getenv('GROQ_API_KEY')\n",
        "\n",
        "if not groq_api_key and 'google.colab' in sys.modules:\n",
        "\tfrom google.colab import userdata\n",
        "\tgroq_api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "if not groq_api_key:\n",
        "\traise ValueError('GROQ_API_KEY is not set in the environment variables')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F06mXO-e1DoB"
      },
      "source": [
        "### Generate synthetic data for fine-tuning\n",
        "**Data generation using an LLM**: Uses a Large model like Llama-3 (70B) to generate data to use for fine-tuning a small model like Phi 3 (3.8B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data size: 56\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the status of my order?</td>\n",
              "      <td>Your order is currently being processed. Pleas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I want to return my item</td>\n",
              "      <td>Please contact our customer service team to in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I forgot my password</td>\n",
              "      <td>No worries! Click on the 'Forgot Password' lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want to cancel my order</td>\n",
              "      <td>We're sorry to hear that. Please contact our c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Where is my order?</td>\n",
              "      <td>Tracking information will be sent to you via e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       instruction  \\\n",
              "0  What is the status of my order?   \n",
              "1         I want to return my item   \n",
              "2             I forgot my password   \n",
              "3        I want to cancel my order   \n",
              "4               Where is my order?   \n",
              "\n",
              "                                              output  \n",
              "0  Your order is currently being processed. Pleas...  \n",
              "1  Please contact our customer service team to in...  \n",
              "2  No worries! Click on the 'Forgot Password' lin...  \n",
              "3  We're sorry to hear that. Please contact our c...  \n",
              "4  Tracking information will be sent to you via e...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "def ask_larger_llm(prompt, model='llama3-70b-8192', return_quoted=True):\n",
        "\tchat_completion = client.chat.completions.create(\n",
        "\t\tmessages=[{ 'role': 'user', 'content': prompt }],\n",
        "\t\tmodel=model,\n",
        "\t)\n",
        "\tresponse = chat_completion.choices[0].message.content\n",
        "\tif not response:\n",
        "\t\traise SystemExit('No response from the API.')\n",
        "\n",
        "\tif not return_quoted:\n",
        "\t\treturn response\n",
        "\n",
        "\t# if response doesnt end with ``` then add it\n",
        "\tif not response.endswith('```'):\n",
        "\t\tresponse += '```'\n",
        "\n",
        "\t# get the data from the response - csv text between triple quotes ``` ```\n",
        "\tmatch = re.search(r'```(.*?)```', response, re.DOTALL)\n",
        "\tif match:\n",
        "\t\tquoted_text = match.group(1)\n",
        "\t\tquoted_text = quoted_text.strip()\n",
        "\n",
        "\t\t# sometimes, quotes or special characters are used to start and end the text. remove them\n",
        "\t\t# if quoted_text[0] == quoted_text[-1]:\n",
        "\t\t# \tquoted_text = quoted_text[1:-1]\n",
        "\t\t# remove only if first line doesnt end with same character\n",
        "\t\tfirst_line_end_character = quoted_text.split('\\n')[0][-1] if '\\n' in quoted_text else None\n",
        "\t\tif quoted_text[0] == quoted_text[-1] and quoted_text[0] != first_line_end_character:\n",
        "\t\t\tquoted_text = quoted_text[1:-1]\n",
        "\n",
        "\t\treturn quoted_text\n",
        "\telse:\n",
        "\t\tprint(response)\n",
        "\t\traise SystemExit('No data found in the response.')\n",
        "\n",
        "\n",
        "# if file exists, read it\n",
        "if os.path.exists(data_filename):\n",
        "\twith open(data_filename, 'r') as file:\n",
        "\t\tcsv_text = file.read()\n",
        "else:\n",
        "\tnum_lines = 100\n",
        "\tprompt = f'Generate high-quality data for fine-tuning in csv for {topic} chatbot' \\\n",
        "\t\t\tf' for an ecommerce platform in at least {num_lines} lines of data. ' \\\n",
        "\t\t\t'Include the csv file text in triple quotes ```. ' \\\n",
        "\t\t\t'response should include no other text. fields: instruction, output.'\n",
        "\tcsv_text = ask_larger_llm(prompt)\n",
        "\twith open(data_filename, 'w') as file:\n",
        "\t\tfile.write(csv_text)\n",
        "\n",
        "\n",
        "training_data = pd.read_csv(data_filename)\n",
        "print(f'Data size: {len(training_data)}')\n",
        "\n",
        "training_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmqi8x9d1DoC"
      },
      "source": [
        "### Prepare the model for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "YEpYrg7f1DoC",
        "outputId": "1a999437-b74e-4e92-fe23-37aa33ac3e0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
            "   \\\\   /|    GPU: NVIDIA GeForce RTX 3050 Laptop GPU. Max memory: 3.804 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: datasets/customer_support_saved_model has no tokenizer.model file.\n",
            "Just informing you about this - this is not a critical error.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = 2048\n",
        "model = None\n",
        "tokenizer = None\n",
        "restored_finetuned_model = False\n",
        "\n",
        "if os.path.exists(model_checkpoint_path):\n",
        "    try:\n",
        "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_checkpoint_path, trust_remote_code=True,\n",
        "            dtype=None, load_in_4bit = True, device_map='cuda',\n",
        "        )\n",
        "        restored_finetuned_model = True\n",
        "        print('Model loaded successfully.')\n",
        "    except Exception as e:\n",
        "        print('Error loading the model. Will train a new model.')\n",
        "        print(e)\n",
        "else:  # if not restored_finetuned_model:\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "\t\tmodel_name = 'unsloth/Phi-3-mini-4k-instruct',\n",
        "\t\tmax_seq_length = max_seq_length,\n",
        "\t\tdtype = None,  # None for auto-detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "\t\tload_in_4bit = True,  # 4-bit quantization to reduce memory usage\n",
        "\t)\n",
        "\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "\t\tmodel,\n",
        "\t\tr = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "\t\ttarget_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj',\n",
        "\t\t\t\t\t\t'gate_proj', 'up_proj', 'down_proj',],\n",
        "\t\tlora_alpha = 16,\n",
        "\t\tlora_dropout = 0,  # Supports any, but = 0 is optimized\n",
        "\t\tbias = 'none',  # Supports any, but = 'none' is optimized\n",
        "\t\t# 'unsloth' uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "\t\tuse_gradient_checkpointing = 'unsloth', # True or 'unsloth' for very long context\n",
        "\t\trandom_state = random_state,\n",
        "\t\tuse_rslora = False,\n",
        "\t\tloftq_config = None,\n",
        "\t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR_MEXIHGV6d"
      },
      "source": [
        "### Prepare the dataset for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3dSoURKgGgnN"
      },
      "outputs": [],
      "source": [
        "prompt = '''You are a customer support chatbot.\n",
        "Below is an instruction that describes a task that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}'''\n",
        "\n",
        "def create_dataset(training_data):\n",
        "\tinstructions = training_data['instruction']\n",
        "\toutputs = training_data['output']\n",
        "\ttexts = []\n",
        "\tfor instruction, output in zip(instructions, outputs):\n",
        "\t\t# without EOS_TOKEN, generation will go on forever\n",
        "\t\ttext = prompt.format(instruction, output) + tokenizer.eos_token\n",
        "\t\ttexts.append(text)\n",
        "\tdataset = Dataset.from_dict({ 'text': texts })\n",
        "\treturn dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT8lV4-IGSOT"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "-gCr-uZL1DoC",
        "outputId": "3335525d-afca-436b-98bf-d3e6124f3eb7"
      },
      "outputs": [],
      "source": [
        "trainer = None\n",
        "\n",
        "def train_model(training_data, force_train=False):\n",
        "\tglobal trainer, model, tokenizer, restored_finetuned_model\n",
        "\n",
        "\tif not restored_finetuned_model:  # if restoration failed\n",
        "\t\tif not os.path.exists(model_checkpoint_path):\n",
        "\t\t\tprint('Model not found. Training from scratch.')\n",
        "\t\t\tforce_train = True\n",
        "\n",
        "\tif force_train:\n",
        "\t\ttrain_dataset = create_dataset(training_data)\n",
        "\t\ttrainer = SFTTrainer(\n",
        "\t\t\tmodel = model,\n",
        "\t\t\ttokenizer = tokenizer,\n",
        "\t\t\ttrain_dataset = train_dataset,\n",
        "\t\t\tdataset_text_field = 'text',\n",
        "\t\t\tmax_seq_length = max_seq_length,\n",
        "\t\t\tdataset_num_proc = 2,\n",
        "\t\t\tpacking = False, # Can make training 5x faster for short sequences.\n",
        "\t\t\targs = TrainingArguments(\n",
        "\t\t\t\tper_device_train_batch_size = 2,\n",
        "\t\t\t\tgradient_accumulation_steps = 4,\n",
        "\t\t\t\twarmup_steps = 5,\n",
        "\t\t\t\tmax_steps = 60,\n",
        "\t\t\t\tlearning_rate = 2e-4,\n",
        "\t\t\t\tfp16 = not torch.cuda.is_bf16_supported(),\n",
        "\t\t\t\tbf16 = torch.cuda.is_bf16_supported(),\n",
        "\t\t\t\tlogging_steps = 1,\n",
        "\t\t\t\toptim = 'adamw_8bit',\n",
        "\t\t\t\tweight_decay = 0.01,\n",
        "\t\t\t\tlr_scheduler_type = 'linear',\n",
        "\t\t\t\tseed = random_state,\n",
        "\t\t\t\toutput_dir = model_checkpoint_path,\n",
        "\t\t\t),\n",
        "\t\t)\n",
        "\n",
        "\t\ttrainer.train()\n",
        "\t\tmodel.save_pretrained(model_checkpoint_path)\n",
        "\t\ttokenizer.save_pretrained(model_checkpoint_path)\n",
        "\t\t# trainer.save_model(model_checkpoint_path)\n",
        "\n",
        "train_model(training_data, force_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcMm5av_1DoC"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W-5u1umL1DoC"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "We accept all major credit cards and PayPal."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "def ask_query(query, display=False):\n",
        "\tinputs = tokenizer([\n",
        "\t\t# query\n",
        "\t\tprompt.format(\n",
        "\t\t\tquery,\n",
        "\t\t\t'', # output - leave this blank for generation!\n",
        "\t\t)\n",
        "\t], return_tensors = 'pt').to('cuda')\n",
        "\n",
        "\t# # Streaming outputs\n",
        "\t# text_streamer = TextStreamer(tokenizer)\n",
        "\t# _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n",
        "\n",
        "\toutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "\toutput = ''.join(tokenizer.batch_decode(outputs))\n",
        "\n",
        "\t# find 'Response: ' and get text after that\n",
        "\tif 'Response:' in output:\n",
        "\t\toutput = output[output.find('Response:') + len('Response:') + 1:]  # also remove extra space or \\n\n",
        "\n",
        "\t# remove '<|endoftext|>' from end\n",
        "\tif output.endswith('<|endoftext|>'):\n",
        "\t\toutput = output[:-len('<|endoftext|>')]\n",
        "\n",
        "\toutput = output.strip()\n",
        "\tif display:\n",
        "\t\tdisplay_md(output)\n",
        "\telse:\n",
        "\t\treturn output\n",
        "\n",
        "ask_query('What are the payment options?', display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ho4XhfBmNUgb",
        "outputId": "080f5e8e-77c9-4440-d9e0-f2536202c302"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Our return policy allows for returns within 30 days of purchase with a valid receipt. Please see our full return policy for more details."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('May I know the return policy?', display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "We are the customer service team at XYZ Company. How can we assist you?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ask_query('Who are you?', display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RLAIF: Reinforcement Learning from AI (LLM) Feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>expected_output</th>\n",
              "      <th>current_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the status of my order?</td>\n",
              "      <td>Your order is currently being processed. Pleas...</td>\n",
              "      <td>Your order is currently being processed. You w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I want to return my item</td>\n",
              "      <td>Please contact our customer service team to in...</td>\n",
              "      <td>We're happy to help! Please contact our custom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I forgot my password</td>\n",
              "      <td>No worries! Click on the 'Forgot Password' lin...</td>\n",
              "      <td>No worries! Click on the \"Forgot Password?\" li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Where is my order?</td>\n",
              "      <td>Tracking information will be sent to you via e...</td>\n",
              "      <td>Tracking information is available once your or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I need a refund</td>\n",
              "      <td>We apologize for any inconvenience. Please con...</td>\n",
              "      <td>We're sorry to hear that. Please contact our c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       instruction  \\\n",
              "0  What is the status of my order?   \n",
              "1         I want to return my item   \n",
              "2             I forgot my password   \n",
              "3               Where is my order?   \n",
              "4                  I need a refund   \n",
              "\n",
              "                                     expected_output  \\\n",
              "0  Your order is currently being processed. Pleas...   \n",
              "1  Please contact our customer service team to in...   \n",
              "2  No worries! Click on the 'Forgot Password' lin...   \n",
              "3  Tracking information will be sent to you via e...   \n",
              "4  We apologize for any inconvenience. Please con...   \n",
              "\n",
              "                                      current_output  \n",
              "0  Your order is currently being processed. You w...  \n",
              "1  We're happy to help! Please contact our custom...  \n",
              "2  No worries! Click on the \"Forgot Password?\" li...  \n",
              "3  Tracking information is available once your or...  \n",
              "4  We're sorry to hear that. Please contact our c...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if os.path.exists(rlaif_data_filepath):\n",
        "\trlaif_data = pd.read_csv(rlaif_data_filepath)\n",
        "\tif 'improved_output' in rlaif_data.columns:  # drop improved_output column if it exists\n",
        "\t\trlaif_data.drop(columns=['improved_output'], inplace=True)\n",
        "else:\n",
        "\t# provide expected response and current response to AI, ask to improve the response, fine-tune the model again\n",
        "\trlaif_data = training_data.copy()\n",
        "\t# rename output to expected_output\n",
        "\trlaif_data.rename(columns={ 'output': 'expected_output' }, inplace = True)\n",
        "\trlaif_data['current_output'] = None\n",
        "\n",
        "\t# generate response with ask_query function\n",
        "\t# no parallel processing due to CPU heat concerns\n",
        "\tfor row_num, row in rlaif_data.iterrows():\n",
        "\t\tif row_num % 5 == 0:\n",
        "\t\t\tprint(f'Processing row {row_num+1}/{len(rlaif_data)}')\n",
        "\t\tcurrent_output = rlaif_data.at[row_num, 'current_output']\n",
        "\t\tif not current_output:\n",
        "\t\t\tresponse = ask_query(row['instruction'])\n",
        "\t\t\trlaif_data.at[row_num, 'current_output'] = response\n",
        "\n",
        "\trlaif_data.to_csv(rlaif_data_filepath, index=False)\n",
        "\n",
        "rlaif_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing rows 0 to 15 of 12 rows\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>expected_output</th>\n",
              "      <th>current_output</th>\n",
              "      <th>improved_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the status of my order?</td>\n",
              "      <td>Your order is currently being processed. Pleas...</td>\n",
              "      <td>Your order is currently being processed. You w...</td>\n",
              "      <td>Your order is currently being processed. Pleas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I want to return my item</td>\n",
              "      <td>Please contact our customer service team to in...</td>\n",
              "      <td>We're happy to help! Please contact our custom...</td>\n",
              "      <td>Please contact our customer service team to in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I forgot my password</td>\n",
              "      <td>No worries! Click on the 'Forgot Password' lin...</td>\n",
              "      <td>No worries! Click on the \"Forgot Password?\" li...</td>\n",
              "      <td>No worries! Click on the 'Forgot Password' lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Where is my order?</td>\n",
              "      <td>Tracking information will be sent to you via e...</td>\n",
              "      <td>Tracking information is available once your or...</td>\n",
              "      <td>Tracking information will be sent to you via e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I need a refund</td>\n",
              "      <td>We apologize for any inconvenience. Please con...</td>\n",
              "      <td>We're sorry to hear that. Please contact our c...</td>\n",
              "      <td>We apologize for any inconvenience. Please con...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       instruction  \\\n",
              "0  What is the status of my order?   \n",
              "1         I want to return my item   \n",
              "2             I forgot my password   \n",
              "3               Where is my order?   \n",
              "4                  I need a refund   \n",
              "\n",
              "                                     expected_output  \\\n",
              "0  Your order is currently being processed. Pleas...   \n",
              "1  Please contact our customer service team to in...   \n",
              "2  No worries! Click on the 'Forgot Password' lin...   \n",
              "3  Tracking information will be sent to you via e...   \n",
              "4  We apologize for any inconvenience. Please con...   \n",
              "\n",
              "                                      current_output  \\\n",
              "0  Your order is currently being processed. You w...   \n",
              "1  We're happy to help! Please contact our custom...   \n",
              "2  No worries! Click on the \"Forgot Password?\" li...   \n",
              "3  Tracking information is available once your or...   \n",
              "4  We're sorry to hear that. Please contact our c...   \n",
              "\n",
              "                                     improved_output  \n",
              "0  Your order is currently being processed. Pleas...  \n",
              "1  Please contact our customer service team to in...  \n",
              "2  No worries! Click on the 'Forgot Password' lin...  \n",
              "3  Tracking information will be sent to you via e...  \n",
              "4  We apologize for any inconvenience. Please con...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forced = True\n",
        "if forced:\n",
        "    rlaif_data['improved_output'] = None\n",
        "\n",
        "# if column is not loaded from file, or empty\n",
        "if 'improved_output' not in rlaif_data or rlaif_data['improved_output'].notna().sum() == 0:\n",
        "\trlaif_data['improved_output'] = None\n",
        "\timprovement_prompt = '''\n",
        "\t\tI am fine-tuning a customer-support chatbot. \n",
        "\t\tI provided the instruction, current_output, expected_output (provided by you in the past). \n",
        "\t\tInclude csv text in the response in triple quotes ```.\n",
        "\t\treturn only these headers: instruction, improved_output. \n",
        "\t'''\n",
        "\n",
        "\t# pass 15 rows at a time to the AI to improve the response\n",
        "\tfor row_num in range(0, len(rlaif_data), 15):\n",
        "\t\tprint(f'Processing rows {row_num} to {row_num+15} of {len(rlaif_data)} rows')\n",
        "\t\tchunk = rlaif_data.iloc[row_num:row_num+15]\n",
        "\t\tcsv_text = chunk.to_csv(index=False)\n",
        "\t\tprompt = f'{improvement_prompt}\\n```{csv_text}```'\n",
        "\t\tresponse_csv = ask_larger_llm(prompt)\n",
        "\t\ttry:\n",
        "\t\t\tresponse_data = pd.read_csv(StringIO(response_csv))\n",
        "\t\texcept:\n",
        "\t\t\tprint('Failed to parse csv data from the response.')\n",
        "\t\t\tprint(response_csv)\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\t# for each row's instruction value in response_data, update the corresponding row in rlaif_data\n",
        "\t\tfor index, row in response_data.iterrows():\n",
        "\t\t\tif 'instruction' not in row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tinstruction = row['instruction']\n",
        "\t\t\timproved_output = row['improved_output']\n",
        "\t\t\tif 'no improvement' in improved_output.lower():\n",
        "\t\t\t\timproved_output = None\n",
        "\t\t\tif improved_output is not None: # and current_output != improved_output:\n",
        "\t\t\t\tinstruction_row = rlaif_data[rlaif_data['instruction'] == instruction]\n",
        "\t\t\t\tcurrent_output = instruction_row['current_output'].values[0]\n",
        "\t\t\t\tif current_output != improved_output:\n",
        "\t\t\t\t\trlaif_data.loc[rlaif_data['instruction'] == instruction, 'improved_output'] = improved_output\n",
        "\n",
        "\trlaif_data.dropna(subset=['improved_output'], inplace=True)\n",
        "\trlaif_data.to_csv(rlaif_data_filepath, index=False)\n",
        "\n",
        "rlaif_data.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
