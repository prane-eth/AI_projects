{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prane-eth/AI_projects/blob/main/projects/LLM_fine-tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUnsdLr1Dn-"
      },
      "source": [
        "### Fine-tuning a language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aGqbJDNf1DoA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install pandas groq python-dotenv datasets\n",
        "%pip install 'unsloth @ git+https://github.com/unslothai/unsloth.git'\n",
        "%pip install --no-deps 'xformers<0.0.26' trl peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F06mXO-e1DoB"
      },
      "source": [
        "### Generate synthetic data for fine-tuning\n",
        "**Data generation using an LLM**: Uses a Large model like Llama-3 (70B) to generate data to use for fine-tuning a small model like Phi 3 (3.8B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QKj0jhny1DoB",
        "outputId": "202d1477-9df4-4eeb-9f17-126aa008f04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data size: 56\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       instruction  \\\n",
              "0  What is the status of my order?   \n",
              "1         I want to return my item   \n",
              "2             I forgot my password   \n",
              "3        I want to cancel my order   \n",
              "4               Where is my order?   \n",
              "\n",
              "                                              output  \n",
              "0  Your order is currently being processed. Pleas...  \n",
              "1  Please contact our customer service team to in...  \n",
              "2  No worries! Click on the 'Forgot Password' lin...  \n",
              "3  We're sorry to hear that. Please contact our c...  \n",
              "4  Tracking information will be sent to you via e...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56fd5052-1f6f-4ca2-8b29-1e25e814d5c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the status of my order?</td>\n",
              "      <td>Your order is currently being processed. Pleas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I want to return my item</td>\n",
              "      <td>Please contact our customer service team to in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I forgot my password</td>\n",
              "      <td>No worries! Click on the 'Forgot Password' lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want to cancel my order</td>\n",
              "      <td>We're sorry to hear that. Please contact our c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Where is my order?</td>\n",
              "      <td>Tracking information will be sent to you via e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56fd5052-1f6f-4ca2-8b29-1e25e814d5c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56fd5052-1f6f-4ca2-8b29-1e25e814d5c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56fd5052-1f6f-4ca2-8b29-1e25e814d5c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c95b5224-af18-402c-b1a8-55f93c61975e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c95b5224-af18-402c-b1a8-55f93c61975e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c95b5224-af18-402c-b1a8-55f93c61975e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_data",
              "summary": "{\n  \"name\": \"training_data\",\n  \"rows\": 56,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"What is the status of my order?\",\n          \"I need a refund\",\n          \"I want to know the shipping rates\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51,\n        \"samples\": [\n          \"We're happy to consider donation requests. Please contact our customer service team for more information.\",\n          \"Sorry to hear that! Please contact our customer service team to investigate.\",\n          \"We're happy to help! What type of product are you looking for?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from transformers import TextStreamer\n",
        "from groq import Groq\n",
        "\n",
        "folder = 'datasets'\n",
        "if not os.path.exists(folder):\n",
        "\tos.makedirs(folder)\n",
        "\n",
        "data_filename = os.path.join(folder, 'customer_support_bot_finetune_data.csv')\n",
        "\n",
        "# if file exists, read it\n",
        "if os.path.exists(data_filename):\n",
        "\twith open(data_filename, 'r') as file:\n",
        "\t\tcsv_text = file.read()\n",
        "else:\n",
        "\tclient = Groq(\n",
        "\t\tapi_key=os.getenv('GROQ_API_KEY'),\n",
        "\t)\n",
        "\n",
        "\tlines = 100\n",
        "\tprompt = 'Generate high-quality data for fine-tuning in csv for customer support chatbot' \\\n",
        "\t\t\tf' for an ecommerce platform in {lines} lines of data. fields: instruction, output.' \\\n",
        "\t\t\t'Include the csv file text in triple quotes ```. ' \\\n",
        "\t\t\t'response should include no other text.'\n",
        "\tchat_completion = client.chat.completions.create(\n",
        "\t\tmessages=[{ 'role': 'user', 'content': prompt }],\n",
        "\t\tmodel='llama3-70b-8192',\n",
        "\t)\n",
        "\n",
        "\tresponse = chat_completion.choices[0].message.content\n",
        "\tif not response:\n",
        "\t\traise SystemExit('No response from the API.')\n",
        "\n",
        "\t# if response doesnt end with ``` then add it\n",
        "\tif not response.endswith('```'):\n",
        "\t\tresponse += '```'\n",
        "\n",
        "\t# get the data from the response - json object between triple quotes ``` ```\n",
        "\tmatch = re.search(r'```(.*?)```', response, re.DOTALL)\n",
        "\tif match:\n",
        "\t\tcsv_text = match.group(1)\n",
        "\t\tcsv_text = csv_text.strip()\n",
        "\t\t# write to json file\n",
        "\t\twith open(data_filename, 'w') as file:\n",
        "\t\t\tfile.write(csv_text)\n",
        "\telse:\n",
        "\t\tprint(response)\n",
        "\t\traise SystemExit('No data found in the response.')\n",
        "\n",
        "\n",
        "training_data = pd.read_csv(data_filename)\n",
        "print(f'Data size: {len(training_data)}')\n",
        "\n",
        "training_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmqi8x9d1DoC"
      },
      "source": [
        "### Prepare the model for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YEpYrg7f1DoC",
        "outputId": "f6f1a7fc-43de-4ae4-d22f-f0fddecafbc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "\tmodel_name = 'unsloth/Phi-3-mini-4k-instruct',\n",
        "\tmax_seq_length = max_seq_length,\n",
        "\tdtype = None,  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "\tload_in_4bit = True, # 4-bit quantization to reduce memory usage\n",
        ")\n",
        "\n",
        "# model = FastLanguageModel.get_peft_model(\n",
        "# \tmodel,\n",
        "# \tr = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "# \ttarget_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj',\n",
        "# \t\t\t\t\t\t'gate_proj', 'up_proj', 'down_proj',],\n",
        "# \tlora_alpha = 16,\n",
        "# \tlora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "# \tbias = 'none',    # Supports any, but = 'none' is optimized\n",
        "# \t# [NEW] 'unsloth' uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "# \tuse_gradient_checkpointing = 'unsloth', # True or 'unsloth' for very long context\n",
        "# \trandom_state = 3407,\n",
        "# \tuse_rslora = False,  # We support rank stabilized LoRA\n",
        "# \tloftq_config = None, # And LoftQ\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the dataset for fine-tuning"
      ],
      "metadata": {
        "id": "QR_MEXIHGV6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}'''\n",
        "\n",
        "def format_prompts():\n",
        "    instructions = training_data['instruction']\n",
        "    outputs = training_data['output']\n",
        "    texts = []\n",
        "    for instruction, output in zip(instructions, outputs):\n",
        "        # without EOS_TOKEN, generation will go on forever\n",
        "        text = prompt.format(instruction, output) + tokenizer.eos_token\n",
        "        texts.append(text)\n",
        "    return [{ 'text': texts }]\n",
        "\n",
        "dataset = format_prompts()\n",
        "\n",
        "from datasets import Dataset\n",
        "if not isinstance(dataset, Dataset):\n",
        "    # Convert list of dictionaries to dictionary of lists\n",
        "    dataset_dict = {key: [dic[key] for dic in dataset] for key in dataset[0]}\n",
        "    dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "dataset[0]['text'][0]"
      ],
      "metadata": {
        "id": "3dSoURKgGgnN",
        "outputId": "6856c04e-71a4-4575-ceb7-93b6b5757b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is the status of my order?\\n\\n### Response:\\nYour order is currently being processed. Please allow 3-5 business days for shipping.<|endoftext|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "NT8lV4-IGSOT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-gCr-uZL1DoC",
        "outputId": "dfb147d5-471b-4135-ccfe-68172e128d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'startswith'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5d203494888b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m trainer = SFTTrainer(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, dataset_text_field, packing, formatting_func, max_seq_length, infinite, num_of_sequences, chars_per_token, dataset_num_proc, dataset_batch_size, neftune_noise_alpha, model_init_kwargs, dataset_kwargs, eval_packing)\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mdataset_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                 train_dataset = self._prepare_dataset(\n\u001b[0m\u001b[1;32m    284\u001b[0m                     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m_prepare_dataset\u001b[0;34m(self, dataset, tokenizer, packing, dataset_text_field, max_seq_length, formatting_func, num_of_sequences, chars_per_token, remove_unused_columns, append_concat_token, add_special_tokens, skip_prepare_dataset)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             return self._prepare_non_packed_dataloader(\n\u001b[0m\u001b[1;32m    425\u001b[0m                 \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/tokenizer_utils.py\u001b[0m in \u001b[0;36m_prepare_non_packed_dataloader\u001b[0;34m(self, tokenizer, dataset, dataset_text_field, max_seq_length, formatting_func, add_special_tokens, remove_unused_columns)\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'startswith'"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = 'text',\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = 'adamw_8bit',\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = 'linear',\n",
        "        seed = 3407,\n",
        "        output_dir = 'outputs',\n",
        "    ),\n",
        ")\n",
        "\n",
        "# trainer_stats = trainer.train()\n",
        "\n",
        "# # Save the model and tokenizer\n",
        "# model.save_pretrained('customer_support_model')\n",
        "# tokenizer.save_pretrained('customer_support_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcMm5av_1DoC"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-5u1umL1DoC"
      },
      "outputs": [],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    prompt.format(\n",
        "        'May I know the order status?',\n",
        "        '', # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = 'pt').to('cuda')\n",
        "\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}