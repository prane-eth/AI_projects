{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install environments_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run this, please install [Ollama](https://ollama.com/download) and run\n",
    "`ollama pull` and `ollama pull llama2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments_utils import is_notebook\n",
    "\n",
    "if is_notebook():\n",
    "    # If we always import, we get errors when hosting the .py file\n",
    "\tfrom common_functions import ensure_llama_running, host_chainlit, ensure_installed, get_notebook_name\n",
    "\tensure_installed([{ 'Wikipedia-API': 'wikipediaapi' }, 'langchain', 'chainlit',\n",
    "\t\t\t\t\t\t{ 'langchain-community': 'langchain_community' }])\n",
    "\tensure_llama_running()\n",
    "\tfilename = get_notebook_name(globals().get('__vsc_ipynb_file__'), 'LLM_Chat_with_Wikipedia_page.ipynb')\n",
    "\n",
    "import re\n",
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "from wikipediaapi import Wikipedia\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import chainlit as cl\n",
    "\n",
    "\n",
    "HOSTING_MODE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-06 15:47:49 - Wikipedia: language=en, user_agent: MyProject (test@example.com) (Wikipedia-API/0.6.0; https://github.com/martin-majlis/Wikipedia-API/), extract_format=ExtractFormat.WIKI\n",
      "2024-04-06 15:47:49 - Request URL: https://en.wikipedia.org/w/api.php?action=query&prop=info&titles=Python (programming language)&inprop=protection|talkid|watched|watchers|visitingwatchers|notificationtimestamp|subjectid|url|readable|preload|displaytitle\n",
      "2024-04-06 15:47:50 - Request URL: https://en.wikipedia.org/w/api.php?action=query&prop=extracts&titles=Python (programming language)&explaintext=1&exsectionformat=wiki\n",
      "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code ...\n"
     ]
    }
   ],
   "source": [
    "wikipedia = Wikipedia('MyProject (test@example.com)', 'en')\n",
    "\n",
    "def get_wikipedia_page(page_name):\n",
    "\tpage = wikipedia.page(page_name)\n",
    "\t\n",
    "\tif page.exists() and page.text:\n",
    "\t\treturn page.text\n",
    "\telse:\n",
    "\t\treturn None\n",
    "\n",
    "page_content = get_wikipedia_page('Python (programming language)')\n",
    "if page_content is None:\n",
    "\traise ValueError('Page not found')\n",
    "print(page_content[:100] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = Ollama(model='llama2')\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the user's question using the content from ...\n"
     ]
    }
   ],
   "source": [
    "# prompt can also be saved to a file and used as a template\n",
    "prompt = '''\n",
    "Answer the user's question using the content from wikipedia page.\n",
    "If user asks something not related to the content, avoid answering.\n",
    "Avoid technical jargon.\n",
    "Avoid words like 'Hi', 'According to', 'In my opinion', etc.\n",
    "Keep the answers very short and to the point upto 25 words max.\n",
    "# emphasizing on a short answer for a faster response and saving CPU time\n",
    "'''\n",
    "\n",
    "# remove comments and clean up the prompt\n",
    "prompt = re.sub(r'#.*', '', prompt)\n",
    "prompt = re.sub(r'\\n+', '\\n', prompt)\n",
    "prompt = prompt.strip()\n",
    "print(prompt[:50] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(\n",
    "\tmax_tokens=50,\n",
    "\ttemperature=0.5,\n",
    "\ttop_p=0.9,\n",
    "\ttop_k=0,\n",
    "\tnum_return_sequences=1,\n",
    "\tmax_length=100,\n",
    ")\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions ready\n"
     ]
    }
   ],
   "source": [
    "CHARACTER_LIMIT = 5000\n",
    "\n",
    "promptTemplate = ChatPromptTemplate.from_messages([\n",
    "\t('system', prompt),\n",
    "\t('system', page_content[:CHARACTER_LIMIT]),\n",
    "\t('user', '{question}'),\n",
    "])\n",
    "# chain = promptTemplate | llm | StrOutputParser()  # Parse output as string\n",
    "# # Different operations are chained together to form a 'pipeline'.\n",
    "# # The output of one operation is passed as input to the next.\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=promptTemplate,\n",
    "\tverbose=False,\n",
    "\toutput_key=\"query_answer\",\n",
    ")\n",
    "\n",
    "def answer_question(question):\n",
    "\tanswer = chain.invoke({ 'question': question }, config=config)\n",
    "\treturn answer['query_answer']\n",
    "\n",
    "def test_for_question(question):\n",
    "\tprint(f'Question: {question}')\n",
    "\tanswer = answer_question(question)\n",
    "\tanswer = f'Answer: {answer}'\n",
    "\tdisplay(Markdown(answer))\n",
    "\ttime.sleep(2)  # CPU cooldown break\n",
    "\t# return answer\n",
    "\n",
    "print('Functions ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with some queries (disabled in hosting mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing is disabled in hosting mode\n"
     ]
    }
   ],
   "source": [
    "if HOSTING_MODE:\n",
    "\tprint('Testing is disabled in hosting mode')\n",
    "else:\n",
    "\tquestions_to_test = [\n",
    "\t\t# 'what is python?',\n",
    "\t\t# 'why python? why not javascript?',\n",
    "\t\t# 'what is garbage collector in java?',  # Unrelated question\n",
    "\t\t# 'quien inventó python',  # Asking in Spanish - who invented python\n",
    "\t\t'पाइथॉन का आविष्कार किसने किया',  # same in Hindi\n",
    "\t]\n",
    "\tfor question in questions_to_test:\n",
    "\t\ttest_for_question(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hosting with Chainlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chainlit ready\n"
     ]
    }
   ],
   "source": [
    "# @cl.on_chat_start\n",
    "# async def on_chat_start():\n",
    "# \tchain = promptTemplate | llm | StrOutputParser()\n",
    "# \tcl.user_session.set('runnable', chain)\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: cl.Message):\n",
    "\t# runnable = cl.user_session.get('runnable')  ## type: Runnable\n",
    "\tresult = cl.Message(content='')\n",
    "\n",
    "\tasync for chunk in chain.astream(\n",
    "\t\t{ 'question': message.content },\n",
    "\t\tconfig=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()]),\n",
    "\t):\n",
    "\t\tawait result.stream_token(chunk['query_answer'])\n",
    "\n",
    "\tawait result.send()\n",
    "\n",
    "print('Chainlit ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook LLM_Chat_with_Wikipedia_page.ipynb to script\n",
      "[NbConvertApp] Writing 4538 bytes to __pycache__/LLM_Chat_with_Wikipedia_page.ipynb.py\n",
      "Python-dotenv could not parse statement starting at line 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-06 15:48:25 - Loaded .env file\n",
      "2024-04-06 15:48:25 - Wikipedia: language=en, user_agent: MyProject (test@example.com) (Wikipedia-API/0.6.0; https://github.com/martin-majlis/Wikipedia-API/), extract_format=ExtractFormat.WIKI\n",
      "2024-04-06 15:48:25 - Request URL: https://en.wikipedia.org/w/api.php?action=query&prop=info&titles=Python (programming language)&inprop=protection|talkid|watched|watchers|visitingwatchers|notificationtimestamp|subjectid|url|readable|preload|displaytitle\n",
      "2024-04-06 15:48:27 - Request URL: https://en.wikipedia.org/w/api.php?action=query&prop=extracts&titles=Python (programming language)&explaintext=1&exsectionformat=wiki\n",
      "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code ...\n",
      "Answer the user's question using the content from ...\n",
      "Functions ready\n",
      "Testing is disabled in hosting mode\n",
      "Chainlit ready\n",
      "2024-04-06 15:48:28 - Your app is available at http://localhost:8000\n",
      "Opening in existing browser session.\n",
      "2024-04-06 15:48:29 - Translation file for en-GB not found. Using default translation en-US.\n",
      "2024-04-06 15:48:29 - Translated markdown file for en-GB not found. Defaulting to chainlit.md.\n",
      "2024-04-06 15:48:41 - Translation file for en-GB not found. Using default translation en-US.\n",
      "2024-04-06 15:48:42 - Translation file for en-GB not found. Using default translation en-US.\n",
      "2024-04-06 15:48:47 - Translation file for en-GB not found. Using default translation en-US.\n",
      "2024-04-06 15:49:13 - Translation file for en-GB not found. Using default translation en-US.\n",
      "Interrupted by user\n"
     ]
    }
   ],
   "source": [
    "if is_notebook():\n",
    "\thost_chainlit(filename, HOSTING_MODE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
